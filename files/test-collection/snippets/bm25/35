Snippets for the query:  Fast algorithm for context-free language recognition or parsing
************************
Total Hits:  11
************************

************************
Document:  CACM-2794.html
************************


State-Space, Problem-Reduction, and Theorem Proving-Some Relationships

This paper suggests a bidirectional relationship
between state-space and problem-reduction 
representations. It presents a formalism based on multiple-input
and multiple-output operators which 
provides a basis for viewing the two types of representations
in this manner.  A representation of the 
<B>language recognition</B> problem which is based on the Cocke
parsing algorithm is used as an illustration. 
 A method for representing problems in first-order logic
in such a way that the inference system employed 
by a resolution-based theorem prover determines whether
the set of clauses is interpreted in the state-spacer 
mode or in the problem-reduction mode is presented.
 The analogous concepts in problem-reduction and 
theorem proving, and the terminology used to refer to them,
are noted.  The relationship between problem-reduction, 
input resolution, and linear resolution is discussed.

CACM February, 1975

VanderBrug, G. J.
Minker, J.

artificial intelligence, state-space representation,
problem-reduction representation, theorem 
proving, language recognition

3.64

CA750205 JB January 12, 1978  8:27 AM

2794	5	2794
2794	5	2794
2794	5	2794


************************

************************
Document:  CACM-2925.html
************************


Optimal Surface Reconstruction from Planar Contours

In many scientific and technical endeavors,
a three-dimensional solid must be reconstructed 
from serial sections, either to aid in the comprehension
of the object's structure or to facilitate its 
automatic manipulation and analysis.  This paper presents
a general solution to the problem of constructing 
a surface over a set of cross-sectional contours. 
This surface, to be composed of triangular tiles, 
is constructed by separately determining an optimal
surface between each pair of consecutive contours.
 Determining such a surface is reduced to the problem
of finding certain minimum cost cycles in a directed 
toroidal graph.  A new fast <B>algorithm for</B> finding such
cycles is utilized.  Also developed is a closed-form 
expression, in term of the number of contour poin ts, for
an upper bound on the number of operations required 
to execute the algorithm.  An illustrated example which
involves the construction of a minimum area surface 
describing a human head is included.

CACM October, 1977

Fuchs, H.
Kedem,Z. M.
Uselton, S. P.

surface reconstruction, contour data, serial sections,
three-dimensional computer graphics, minimum 
cost paths, continuous tone displays

5.25 5.32 8.2

CA771001 JB December 27, 1977  12:40 PM

2925	5	2925
2925	5	2925
2925	5	2925


************************

************************
Document:  CACM-3135.html
************************


Detection of Three-Dimensional Patterns of Atoms in Chemical Structures

An <B>algorithm for</B> detecting occurrences of a three-dimensional pattern of
objects within a larger structure is presented.  The search technique
presented uses the geometric structure of the pattern to define
characteristics demanded of candidates for matching. This is useful
in cases where the properties of each atom, considered individually,
do not adequately limit the number of sets of possible matchings.
Several applications of this technique in the field of chemistry
are: (1) in pharmacology: searching for a common constellation
of atoms in molecules possessing similar biological activities;
(2) in X-ray crystallography: fitting a structure or a structural fragment
to a set of peaks in the electron-density distribution of
a Fourier map; (3) in chemical documentation; retrieving from
a file the structures containing specified substructures.

CACM April, 1979

Lesk, A.

Three-dimensional pattern recognition, chemical
structure search, information retrieval, crystal
-structure analysis, drug analysis and design

3.13 3.63 3.74

CA790401 DH May 21, 1979  10:50 AM

2521	5	3135
3135	5	3135
3135	5	3135
3135	5	3135
2028	6	3135
2031	6	3135
3135	6	3135


************************

************************
Document:  CACM-2301.html
************************


Generating Parsers for Affix Grammars

Affix grammars are two-level grammars which
are similar to van Wijngaarden's two-level grammars 
used in the definition of Algol 68.  Affix grammars are shown
by Koster to be equal in power to van Wijngaarden 
grammars.  They are much more suited to parsing than
are the latter, however.  Koster, the inventor of 
affix based on recursive procedures.  This paper presents
a bottom-up scheme f<B>or parsing</B> them, based 
on an extension of Floyd Production Language (FPL).  Included
is an algorithm, similar to that of DeRemer's, 
for converting a large class of affix grammars into FPL.
 The paper concludes by discussing briefly the 
applicabilities of the conversion algorithm and affix
grammars in general, and some possible extensions 
to Koster's definition of affix grammars.

CACM August, 1972

Crowe, D.

algorithmic language processing,bottom-up parsing,
Floyd Production Language, parsing, syntax 
directed compiling, translator writing systems, two-level grammars

3.42 4.12 4.13 4.20 5.23

CA720801 JB January 30, 1978  10:21 AM

2301	5	2301
2301	5	2301
2301	5	2301
2886	5	2301
2301	6	2301


************************

************************
Document:  CACM-2880.html
************************


A Fast Division Technique for Constant Divisors

A fast <B>algorithm for</B> division by constant divisors
is presented.  The method has proved very 
useful implemented as microcode ona binary machine,
and can be adapted directly into hardware.  The 
mathematical foundations of the algorithm are presented
as well as some performance measures.

CACM February, 1976

Artzy, E.
Hinds, J. A.
Saal, H. J.

constant divisors, division algorithms,
bit addressable memory, microprogram

4.13 4.49 6.32

CA760207 JB January 5, 1978  8:48 AM

2880	5	2880
2880	5	2880
2880	5	2880


************************

************************
Document:  CACM-2112.html
************************


Translation Equations

Input limited transduction expressions, or translation equations,
are used to describe the syntax and left-context sensitive semantics for 
<B>context-free language</B>s.  A formal procedure is given for deriving from
a set of translation equations the specifications for a pushdown translator.
The translator consists of Mealy form finite-state automata interacting
by means of a pushdown stack.  Within the framework described string 
recognition and parsing may be treated as special cases of the translation 
problem.

CACM February, 1970

Vere, S.

automata, Turing machines, regular expression, transduction
expression, context-free languages, translation, recognizers,
parsing, meta-compilers, pushdown transducer, syntax
directed compilers, finite state automata

4.10 4.12 4.20 5.22

CA700203 JB February 14, 1978  10:49 AM

1323	4	2112
1358	4	2112
1380	4	2112
1665	4	2112
1781	4	2112
1787	4	2112
1989	4	2112
2112	4	2112
2534	4	2112
2541	4	2112
2698	4	2112
2733	4	2112
2820	4	2112
3073	4	2112
3155	4	2112
2112	5	2112
2112	5	2112
2112	5	2112
799	5	2112


************************

************************
Document:  CACM-1012.html
************************


Formal Parsing Systems

Automatic syntactic analysis has recently become
important for both natural language data processing 
and syntax-directed compilers.  A formal parsing system
G = (V,u,T,R) consists of two finite disjoint 
vocabularies, V and T, a many-many map, u, from V onto
T, and a recursive set R of strings in T called 
syntactic sentence classes.  Every program for automatic
syntactic analysis determines a formal parsing 
system.  A directed production analyzer (I,T,X,p) is a
nondeterministic pushdown-store machine with internal 
vocabulary I, input vocabulary T, and all productions
of p in the form:  (Z,a) -> aY1 ... Ym where  Z, 
Yi are elements of the set I and a is an element of the
set T.  Every <B>context-free language</B> can be analyzed 
by a directed production analyzer.  The Kuno-Oettinger
multiple-path syntactic analyzer for English is 
a concrete example of a directed production analyzer
and of a working parsing algorithm.  The connection 
between structures assigned by the analyzer and those of
a conventional phrase structure grammar is examined 
in this paper.

CACM August, 1964

Greibach, S. A.

CA640818 JB March 9, 1978  6:30 PM

1012	5	1012
1012	5	1012
1012	5	1012
1225	5	1012
1350	5	1012
1945	5	1012
823	6	1012
914	6	1012
915	6	1012
917	6	1012
984	6	1012
989	6	1012
990	6	1012
1012	6	1012
1012	6	1012
1012	6	1012
1084	6	1012
1098	6	1012
1122	6	1012
1138	6	1012
1139	6	1012
1141	6	1012
1200	6	1012
1223	6	1012
1225	6	1012
1265	6	1012
1265	6	1012
1336	6	1012
1396	6	1012
1399	6	1012
1455	6	1012
1477	6	1012
1487	6	1012
1491	6	1012
1496	6	1012
483	6	1012
584	6	1012
669	6	1012
680	6	1012
680	6	1012
680	6	1012
763	6	1012


************************

************************
Document:  CACM-1265.html
************************


On the Relative Efficiencies of Context-Free Grammar Recognizers

A number of diverse recognition procedures
that have been proposed f<B>or parsing</B> sentences with 
respect to a context-free grammar are described in this
paper by means of a common device.  Each procedure 
is defined by giving an algorithm for obtaining a nondeterministic
Turing Machine recognizer that is 
equivalent to a given context-free grammar.  The formalization
of the Turing Machine has been chosen 
to make possible particularly simple description of
the parsing procedures considered.  An attempt has 
been made to compare recognition efficiencies for the
procedures defined.  For a few simple grammars 
and sentences a formal comparison has been made.  Empirical
comparison of the recognition of more realistic 
programming languages such as LISP and ALGOL has been
made by means of a program which simulates the 
Turing Machine on the Univac M-460 computer.  Several
algorithms for producing grammars equivalent to 
a given context-free grammar have been considered, and
the increase in recognition efficiency they afford 
has been empirically investigated.

CACM May, 1965

Griffiths, T. V.
Petrick, S. R.

CA650506 JB March 7, 1978  2:38 PM

1046	4	1265
1062	4	1265
1086	4	1265
1105	4	1265
1121	4	1265
1132	4	1265
1139	4	1265
1139	4	1265
1139	4	1265
1140	4	1265
1151	4	1265
1234	4	1265
1234	4	1265
1263	4	1265
1263	4	1265
1265	4	1265
1265	4	1265
1265	4	1265
1265	4	1265
1265	4	1265
1270	4	1265
1323	4	1265
1358	4	1265
1379	4	1265
1380	4	1265
1453	4	1265
1464	4	1265
1484	4	1265
1491	4	1265
1496	4	1265
1498	4	1265
1613	4	1265
1614	4	1265
1665	4	1265
1781	4	1265
1781	4	1265
1781	4	1265
1824	4	1265
1825	4	1265
1860	4	1265
2083	4	1265
2126	4	1265
2178	4	1265
2179	4	1265
2252	4	1265
2325	4	1265
2341	4	1265
2546	4	1265
2546	4	1265
464	4	1265
2645	4	1265
2652	4	1265
2684	4	1265
2769	4	1265
2842	4	1265
2929	4	1265
2934	4	1265
584	4	1265
3069	4	1265
631	4	1265
653	4	1265
669	4	1265
679	4	1265
680	4	1265
691	4	1265
720	4	1265
759	4	1265
761	4	1265
763	4	1265
763	4	1265
795	4	1265
799	4	1265
945	4	1265
949	4	1265
989	4	1265
1265	5	1265
1265	5	1265
1265	5	1265
1350	5	1265
1399	5	1265
1659	5	1265
1768	5	1265
1781	5	1265
1945	5	1265
2110	5	1265
404	5	1265
464	5	1265
3094	5	1265
3184	5	1265
631	5	1265
635	5	1265
823	6	1265
123	6	1265
196	6	1265
914	6	1265
915	6	1265
917	6	1265
919	6	1265
984	6	1265
989	6	1265
990	6	1265
990	6	1265
1007	6	1265
1012	6	1265
1012	6	1265
1046	6	1265
1084	6	1265
1098	6	1265
1122	6	1265
1131	6	1265
1138	6	1265
1139	6	1265
1139	6	1265
1140	6	1265
1141	6	1265
1141	6	1265
1149	6	1265
1198	6	1265
1200	6	1265
1215	6	1265
1223	6	1265
1223	6	1265
1225	6	1265
1225	6	1265
1265	6	1265
1265	6	1265
1265	6	1265
1265	6	1265
1265	6	1265
1265	6	1265
1265	6	1265
1265	6	1265
1303	6	1265
1323	6	1265
1336	6	1265
1350	6	1265
1358	6	1265
1366	6	1265
1396	6	1265
1399	6	1265
1421	6	1265
1455	6	1265
1460	6	1265
1462	6	1265
1463	6	1265
1467	6	1265
1468	6	1265
1477	6	1265
1477	6	1265
1487	6	1265
1491	6	1265
1491	6	1265
1496	6	1265
1496	6	1265
1531	6	1265
1535	6	1265
1565	6	1265
1601	6	1265
1602	6	1265
1613	6	1265
1614	6	1265
1626	6	1265
1641	6	1265
1671	6	1265
1697	6	1265
1781	6	1265
1781	6	1265
1787	6	1265
1788	6	1265
205	6	1265
224	6	1265
249	6	1265
288	6	1265
316	6	1265
381	6	1265
398	6	1265
11	6	1265
2179	6	1265
2645	6	1265
404	6	1265
410	6	1265
463	6	1265
464	6	1265
483	6	1265
483	6	1265
3184	6	1265
3188	6	1265
584	6	1265
584	6	1265
600	6	1265
669	6	1265
680	6	1265
680	6	1265
680	6	1265
691	6	1265
763	6	1265
763	6	1265
799	6	1265


************************



On the Relative Efficiencies of Context-Free Grammar Recognizers

A number of diverse recognition procedures
that have been proposed for parsing sentences with 
respect to a context-free grammar are described in this
paper by means of a common device.  Each procedure 
is defined by giving an <B>algorithm for</B> obtaining a nondeterministic
Turing Machine recognizer that is 
equivalent to a given context-free grammar.  The formalization
of the Turing Machine has been chosen 
to make possible particularly simple description of
the parsing procedures considered.  An attempt has 
been made to compare recognition efficiencies for the
procedures defined.  For a few simple grammars 
and sentences a formal comparison has been made.  Empirical
comparison of the recognition of more realistic 
programming languages such as LISP and ALGOL has been
made by means of a program which simulates the 
Turing Machine on the Univac M-460 computer.  Several
algorithms for producing grammars equivalent to 
a given context-free grammar have been considered, and
the increase in recognition efficiency they afford 
has been empirically investigated.

CACM May, 1965

Griffiths, T. V.
Petrick, S. R.

CA650506 JB March 7, 1978  2:38 PM

1046	4	1265
1062	4	1265
1086	4	1265
1105	4	1265
1121	4	1265
1132	4	1265
1139	4	1265
1139	4	1265
1139	4	1265
1140	4	1265
1151	4	1265
1234	4	1265
1234	4	1265
1263	4	1265
1263	4	1265
1265	4	1265
1265	4	1265
1265	4	1265
1265	4	1265
1265	4	1265
1270	4	1265
1323	4	1265
1358	4	1265
1379	4	1265
1380	4	1265
1453	4	1265
1464	4	1265
1484	4	1265
1491	4	1265
1496	4	1265
1498	4	1265
1613	4	1265
1614	4	1265
1665	4	1265
1781	4	1265
1781	4	1265
1781	4	1265
1824	4	1265
1825	4	1265
1860	4	1265
2083	4	1265
2126	4	1265
2178	4	1265
2179	4	1265
2252	4	1265
2325	4	1265
2341	4	1265
2546	4	1265
2546	4	1265
464	4	1265
2645	4	1265
2652	4	1265
2684	4	1265
2769	4	1265
2842	4	1265
2929	4	1265
2934	4	1265
584	4	1265
3069	4	1265
631	4	1265
653	4	1265
669	4	1265
679	4	1265
680	4	1265
691	4	1265
720	4	1265
759	4	1265
761	4	1265
763	4	1265
763	4	1265
795	4	1265
799	4	1265
945	4	1265
949	4	1265
989	4	1265
1265	5	1265
1265	5	1265
1265	5	1265
1350	5	1265
1399	5	1265
1659	5	1265
1768	5	1265
1781	5	1265
1945	5	1265
2110	5	1265
404	5	1265
464	5	1265
3094	5	1265
3184	5	1265
631	5	1265
635	5	1265
823	6	1265
123	6	1265
196	6	1265
914	6	1265
915	6	1265
917	6	1265
919	6	1265
984	6	1265
989	6	1265
990	6	1265
990	6	1265
1007	6	1265
1012	6	1265
1012	6	1265
1046	6	1265
1084	6	1265
1098	6	1265
1122	6	1265
1131	6	1265
1138	6	1265
1139	6	1265
1139	6	1265
1140	6	1265
1141	6	1265
1141	6	1265
1149	6	1265
1198	6	1265
1200	6	1265
1215	6	1265
1223	6	1265
1223	6	1265
1225	6	1265
1225	6	1265
1265	6	1265
1265	6	1265
1265	6	1265
1265	6	1265
1265	6	1265
1265	6	1265
1265	6	1265
1265	6	1265
1303	6	1265
1323	6	1265
1336	6	1265
1350	6	1265
1358	6	1265
1366	6	1265
1396	6	1265
1399	6	1265
1421	6	1265
1455	6	1265
1460	6	1265
1462	6	1265
1463	6	1265
1467	6	1265
1468	6	1265
1477	6	1265
1477	6	1265
1487	6	1265
1491	6	1265
1491	6	1265
1496	6	1265
1496	6	1265
1531	6	1265
1535	6	1265
1565	6	1265
1601	6	1265
1602	6	1265
1613	6	1265
1614	6	1265
1626	6	1265
1641	6	1265
1671	6	1265
1697	6	1265
1781	6	1265
1781	6	1265
1787	6	1265
1788	6	1265
205	6	1265
224	6	1265
249	6	1265
288	6	1265
316	6	1265
381	6	1265
398	6	1265
11	6	1265
2179	6	1265
2645	6	1265
404	6	1265
410	6	1265
463	6	1265
464	6	1265
483	6	1265
483	6	1265
3184	6	1265
3188	6	1265
584	6	1265
584	6	1265
600	6	1265
669	6	1265
680	6	1265
680	6	1265
680	6	1265
691	6	1265
763	6	1265
763	6	1265
799	6	1265


************************

************************
Document:  CACM-1350.html
************************


The Augmented Predictive Analyzer for Context-Free
Languages-Its Relative Efficiency

It has been proven by Greibach that for a given
context-free grammar G, a standard-form grammar 
Gs can be constructed, which generates the same languages
as is generated by G and whose rules are all 
of the form Z --> cY(1) ... Y(m), (m >= O) where Z and
Y(i) are intermediate symbols and c a terminal 
symbol.  Since the predictive analyzer at Harvard uses
a standard-form grammar, it can accept the language 
of any context-free Grammar G, given an equivalent standard-form
grammar Gs.  The structural descriptions 
SD(Gs,X) assigned to a given sentence X by the predictive
analyzer, however, are usually different from 
the structural descriptions SD(G,X) assigned to the
same sentence by the original context-free grammar 
G from which Gs is derived.  In Section 1, an algorithm,
originally due to Abbott is described standard-form 
grammar each of whose rules is in standard form, supplemented
by additional information describing its 
derivation from the original context-free grammar. 
A technique for performing the SD(Gs,X) to SD(G,X) 
transformation effectively is also described.  In section
2, the augmented predictive analyzer as a parsing 
algorithm for arbitrary <B>context-free language</B>s is compared
with two other parsing algorithms: a selective 
top-to-bottom algorithm similar to Irons' "error correcting
parse algorithm" and an immediate constituent 
analyzer which is an extension of Sakai-Cocke's algorithm
for normal grammars.  The comparison is based 
upon several criteria of efficiency, covering core-storage
requirements, complexities of the programs 
and processing time.

CACM November, 1966

Kuno,S.

CA661108 JB March 2, 1978  3:11 PM

1225	4	1350
1225	4	1350
1350	4	1350
1350	4	1350
1350	4	1350
1350	4	1350
1350	4	1350
1399	4	1350
1646	4	1350
1659	4	1350
1659	4	1350
1768	4	1350
1781	4	1350
1781	4	1350
1856	4	1350
1945	4	1350
1945	4	1350
1945	4	1350
2050	4	1350
2110	4	1350
2650	4	1350
2698	4	1350
2708	4	1350
3093	4	1350
3094	4	1350
1012	5	1350
1225	5	1350
1265	5	1350
1350	5	1350
1350	5	1350
1350	5	1350
1399	5	1350
1659	5	1350
680	5	1350
1225	6	1350
1265	6	1350
1350	6	1350
1671	6	1350
1697	6	1350


************************



The Augmented Predictive Analyzer for Context-Free
Languages-Its Relative Efficiency

It has been proven by Greibach that for a given
context-free grammar G, a standard-form grammar 
Gs can be constructed, which generates the same languages
as is generated by G and whose rules are all 
of the form Z --> cY(1) ... Y(m), (m >= O) where Z and
Y(i) are intermediate symbols and c a terminal 
symbol.  Since the predictive analyzer at Harvard uses
a standard-form grammar, it can accept the language 
of any context-free Grammar G, given an equivalent standard-form
grammar Gs.  The structural descriptions 
SD(Gs,X) assigned to a given sentence X by the predictive
analyzer, however, are usually different from 
the structural descriptions SD(G,X) assigned to the
same sentence by the original context-free grammar 
G from which Gs is derived.  In Section 1, an algorithm,
originally due to Abbott is described standard-form 
grammar each of whose rules is in standard form, supplemented
by additional information describing its 
derivation from the original context-free grammar. 
A technique for performing the SD(Gs,X) to SD(G,X) 
transformation effectively is also described.  In section
2, the augmented predictive analyzer as a parsing 
<B>algorithm for</B> arbitrary context-free languages is compared
with two other parsing algorithms: a selective 
top-to-bottom algorithm similar to Irons' "error correcting
parse algorithm" and an immediate constituent 
analyzer which is an extension of Sakai-Cocke's algorithm
for normal grammars.  The comparison is based 
upon several criteria of efficiency, covering core-storage
requirements, complexities of the programs 
and processing time.

CACM November, 1966

Kuno,S.

CA661108 JB March 2, 1978  3:11 PM

1225	4	1350
1225	4	1350
1350	4	1350
1350	4	1350
1350	4	1350
1350	4	1350
1350	4	1350
1399	4	1350
1646	4	1350
1659	4	1350
1659	4	1350
1768	4	1350
1781	4	1350
1781	4	1350
1856	4	1350
1945	4	1350
1945	4	1350
1945	4	1350
2050	4	1350
2110	4	1350
2650	4	1350
2698	4	1350
2708	4	1350
3093	4	1350
3094	4	1350
1012	5	1350
1225	5	1350
1265	5	1350
1350	5	1350
1350	5	1350
1350	5	1350
1399	5	1350
1659	5	1350
680	5	1350
1225	6	1350
1265	6	1350
1350	6	1350
1671	6	1350
1697	6	1350


************************

