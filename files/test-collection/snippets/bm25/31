Snippets for the query:  I'd like to find articles describing graph algorithms that are based on the eigenvalue decomposition (or singular value decomposition) of the ajacency matrix for the graph. I'm especially interested in any heuristic algorithms for graph coloring and graph isomorphism using this method.
************************
Total Hits:  148
************************

************************
Document:  CACM-2890.html
************************


On Quadratic Adaptive Routing Algorithms

Two analytic models of a store-and-forward communications
network are constructed, one to find 
the optimal message routing and the other to illustrate
the equilibrium (stationary state) maintained 
by an adaptive routing algorithm.  These models show that
adaptive routing does not satisfy the necessary 
conditions for an optimal routing,  Adaptive routing tends
to overuse the direct path and underuse alternate 
routes because it does not consider the impact of its
current routing decision <B>on the</B> future state of 
the network.  The form of the optimality conditions suggests
that a modification of the adaptive algorithm 
will result in optimality.  The modification requires
the substitution of a quadratic bias term instead 
of a linear one in the routing table maintained at each
network node.  Simulation results are presented 
which confirm the theoretical analysis for a simple network.

CACM January, 1976

Agnew, C. E.

routing algorithms, adaptive routing, quadratic routing,
alternate routing, store-and-forward network, 
distributed network, computer network, message switching

3.81 8.0 8.1 8.3

CA760103 JB January 5, 1978  10:37 AM

2890	5	2890
2890	5	2890
2890	5	2890


************************



On Quadratic Adaptive Routing Algorithms

Two analytic models of a store-and-forward communications
network are constructed, one <B>to find</B> 
the optimal message routing and the other to illustrate
the equilibrium (stationary state) maintained 
by an adaptive routing algorithm.  These models show that
adaptive routing does not satisfy the necessary 
conditions for an optimal routing,  Adaptive routing tends
to overuse the direct path and underuse alternate 
routes because it does not consider the impact of its
current routing decision on the future state of 
the network.  The form of the optimality conditions suggests
that a modification of the adaptive algorithm 
will result in optimality.  The modification requires
the substitution of a quadratic bias term instead 
of a linear one in the routing table maintained at each
network node.  Simulation results are presented 
which confirm the theoretical analysis for a simple network.

CACM January, 1976

Agnew, C. E.

routing algorithms, adaptive routing, quadratic routing,
alternate routing, store-and-forward network, 
distributed network, computer network, message switching

3.81 8.0 8.1 8.3

CA760103 JB January 5, 1978  10:37 AM

2890	5	2890
2890	5	2890
2890	5	2890


************************



On Quadratic Adaptive Routing Algorithms

Two analytic models of a store-and-forward communications
network are constructed, one to find 
the optimal message routing and the other to illustrate
the equilibrium (stationary state) maintained 
by an adaptive routing algorithm.  These models show that
adaptive routing does not satisfy the necessary 
conditions for an optimal routing,  Adaptive routing tends
to overuse the direct path and underuse alternate 
routes because it does not consider the impact of its
current routing decision on the future state of 
the network.  The form <B>of the</B> optimality conditions suggests
that a modification of the adaptive algorithm 
will result in optimality.  The modification requires
the substitution of a quadratic bias term instead 
of a linear one in the routing table maintained at each
network node.  Simulation results are presented 
which confirm the theoretical analysis for a simple network.

CACM January, 1976

Agnew, C. E.

routing algorithms, adaptive routing, quadratic routing,
alternate routing, store-and-forward network, 
distributed network, computer network, message switching

3.81 8.0 8.1 8.3

CA760103 JB January 5, 1978  10:37 AM

2890	5	2890
2890	5	2890
2890	5	2890


************************

************************
Document:  CACM-1847.html
************************


An Algorithm for Finding a Fundamental Set of Cycles of a Graph

A fast method is presented for finding a fundamental
set of cycles for an undirected finite 
graph.  A spanning tree is grown and the vertices examined
in turn, unexamined vertices being stored 
in a pushdown list to await examination.  One stage
in the process is to take the top element v of the 
pushdown list and examine it, i.e. inspect all those
edges (v,z) of the graph for which z has not yet 
been examined.  If z is already in the tree, a fundamental
cycle is added; if not, the edge (v,z) is 
placed in the tree.  There is exactly one such stage
for each of the n vertices of the graph.  For large 
n, the store required in creases as n^2 and the time as
n^g where g depends <B>on the</B> type of graph involved. 
 g is bounded below by 2 and above by 3, and it is shown
that both bounds are attained.  In terms of 
storage our algorithm is similar to that of Gotlieb and
Corneil and superior to that of Welch; in terms 
of speed it is similar to that of Welch and superior
to that of Gotlieb and Corneil.  Testsshow our 
algorithm to be remarkably efficient (g=2) on random graphs.

CACM September, 1969

Paton, K.

fundamental cycle set, graph, algorithm, cycle, spanning tree

5.32

CA690909 JB February 15, 1978  4:29 PM

1847	4	1847
1961	4	1847
2052	4	1847
1504	5	1847
1847	5	1847
1847	5	1847
1847	5	1847
1961	5	1847
2177	5	1847
2763	5	1847
1369	6	1847
1504	6	1847
1847	6	1847
1847	6	1847
1847	6	1847


************************



An Algorithm for Finding a Fundamental Set of Cycles of a Graph

A fast method is presented for finding a fundamental
set of cycles for an undirected finite 
graph.  A spanning tree is grown and the vertices examined
in turn, unexamined vertices being stored 
in a pushdown list to await examination.  One stage
in the process is to take the top element v <B>of the</B> 
pushdown list and examine it, i.e. inspect all those
edges (v,z) of the graph for which z has not yet 
been examined.  If z is already in the tree, a fundamental
cycle is added; if not, the edge (v,z) is 
placed in the tree.  There is exactly one such stage
for each of the n vertices of the graph.  For large 
n, the store required in creases as n^2 and the time as
n^g where g depends on the type of graph involved. 
 g is bounded below by 2 and above by 3, and it is shown
that both bounds are attained.  In terms of 
storage our algorithm is similar to that of Gotlieb and
Corneil and superior to that of Welch; in terms 
of speed it is similar to that of Welch and superior
to that of Gotlieb and Corneil.  Testsshow our 
algorithm to be remarkably efficient (g=2) on random graphs.

CACM September, 1969

Paton, K.

fundamental cycle set, graph, algorithm, cycle, spanning tree

5.32

CA690909 JB February 15, 1978  4:29 PM

1847	4	1847
1961	4	1847
2052	4	1847
1504	5	1847
1847	5	1847
1847	5	1847
1847	5	1847
1961	5	1847
2177	5	1847
2763	5	1847
1369	6	1847
1504	6	1847
1847	6	1847
1847	6	1847
1847	6	1847


************************



An Algorithm for Finding a Fundamental Set of Cycles of a Graph

A fast method is presented for finding a fundamental
set of cycles for an undirected finite 
graph.  A spanning tree is grown and the vertices examined
in turn, unexamined vertices being stored 
in a pushdown list to await examination.  One stage
in the process is to take the top element v of the 
pushdown list and examine it, i.e. inspect all those
edges (v,z) of the graph for which z has not yet 
been examined.  If z is already in the tree, a fundamental
cycle is added; if not, the edge (v,z) is 
placed in the tree.  There is exactly one such stage
for each of the n vertices of <B>the graph.</B>  For large 
n, the store required in creases as n^2 and the time as
n^g where g depends on the type of graph involved. 
 g is bounded below by 2 and above by 3, and it is shown
that both bounds are attained.  In terms of 
storage our algorithm is similar to that of Gotlieb and
Corneil and superior to that of Welch; in terms 
of speed it is similar to that of Welch and superior
to that of Gotlieb and Corneil.  Testsshow our 
algorithm to be remarkably efficient (g=2) on random graphs.

CACM September, 1969

Paton, K.

fundamental cycle set, graph, algorithm, cycle, spanning tree

5.32

CA690909 JB February 15, 1978  4:29 PM

1847	4	1847
1961	4	1847
2052	4	1847
1504	5	1847
1847	5	1847
1847	5	1847
1847	5	1847
1961	5	1847
2177	5	1847
2763	5	1847
1369	6	1847
1504	6	1847
1847	6	1847
1847	6	1847
1847	6	1847


************************

************************
Document:  CACM-2453.html
************************


Information Theory Applied to the Conversion
of Decision Tables to Computer Programs

Using ideas from informati<B>on the</B>ory, this paper
develops a heuristic algorithm that converts 
a limited entry decision table to a tree structured computer
program with near minimum average processing 
time.  The method is applicable to any limited entry
decision table and does not require that actions 
have single rules or that the cost of testing conditions
be equal.  It is thus more general than the 
previously published heuristic algorithms.  Compared
to the optimal algorithm of Reinwald and Soland, 
this algorithm is easy to code and takes a much smaller
translation time; it is thus felt that it is 
more useful in practice.  The algorithm is well suited for
manual conversion of decision tables to flowcharts.

CACM September, 1973

Ganapathy, S.
Rajaraman, V.

decision tables, optimum computer programs, information measure

3.50 4.12 5.6

CA730902 JB January 23, 1978  10:01 AM

1237	4	2453
1354	4	2453
1549	4	2453
1564	4	2453
1684	4	2453
2053	4	2453
2053	4	2453
2220	4	2453
2220	4	2453
2221	4	2453
2273	4	2453
2273	4	2453
2273	4	2453
2273	4	2453
2453	4	2453
2453	4	2453
2453	4	2453
2453	4	2453
2453	4	2453
2517	4	2453
2598	4	2453
2598	4	2453
2726	4	2453
2726	4	2453
2726	4	2453
2856	4	2453
2856	4	2453
2856	4	2453
2856	4	2453
3034	4	2453
3113	4	2453
1172	5	2453
1354	5	2453
2053	5	2453
2220	5	2453
2453	5	2453
2453	5	2453
2453	5	2453
2598	5	2453
2856	5	2453
753	5	2453
1172	6	2453
1172	6	2453
1327	6	2453
1354	6	2453
1548	6	2453
2053	6	2453
2220	6	2453
2220	6	2453
2263	6	2453
2453	6	2453
2453	6	2453
2598	6	2453
2691	6	2453


************************



Information Theory Applied to the Conversion
of Decision Tables to Computer Programs

Using ideas from information theory, this paper
develops a heuristic algorithm that converts 
a limited entry decision table to a tree structured computer
program with near minimum average processing 
time.  The method is applicable to any limited entry
decision table and does not require that actions 
have single rules or that the cost of testing conditions
be equal.  It is thus more general than the 
previously published <B>heuristic algorithms</B>.  Compared
to the optimal algorithm of Reinwald and Soland, 
this algorithm is easy to code and takes a much smaller
translation time; it is thus felt that it is 
more useful in practice.  The algorithm is well suited for
manual conversion of decision tables to flowcharts.

CACM September, 1973

Ganapathy, S.
Rajaraman, V.

decision tables, optimum computer programs, information measure

3.50 4.12 5.6

CA730902 JB January 23, 1978  10:01 AM

1237	4	2453
1354	4	2453
1549	4	2453
1564	4	2453
1684	4	2453
2053	4	2453
2053	4	2453
2220	4	2453
2220	4	2453
2221	4	2453
2273	4	2453
2273	4	2453
2273	4	2453
2273	4	2453
2453	4	2453
2453	4	2453
2453	4	2453
2453	4	2453
2453	4	2453
2517	4	2453
2598	4	2453
2598	4	2453
2726	4	2453
2726	4	2453
2726	4	2453
2856	4	2453
2856	4	2453
2856	4	2453
2856	4	2453
3034	4	2453
3113	4	2453
1172	5	2453
1354	5	2453
2053	5	2453
2220	5	2453
2453	5	2453
2453	5	2453
2453	5	2453
2598	5	2453
2856	5	2453
753	5	2453
1172	6	2453
1172	6	2453
1327	6	2453
1354	6	2453
1548	6	2453
2053	6	2453
2220	6	2453
2220	6	2453
2263	6	2453
2453	6	2453
2453	6	2453
2598	6	2453
2691	6	2453


************************

************************
Document:  CACM-3100.html
************************


An Interference Matching Technique for Inducing Abstractions

A method for inducing knowledge by abstraction
from a sequence of training examples is described. 
 The proposed method, interference matching, induces abstractions
by finding relational properties common 
to two or more exemplars.  Three tasks solved by a program
that uses an interference-matching algorithm 
are presented.  Several problems concerning the description
<B>of the</B> training examples and the adequacy 
of interference matching are discussed, and directions
for future research are considered.

CACM May, 1978

Hayes-Roth, F.
McDermott, J.

Rule induction, knowledge acquisition, partial
matching, interference, graph matching, learning, 
induction, knowledge representation, informal retrieval,
abstraction, generalization, language learning, 
complexity, predicate discovery.

3.36 3.61 3.62 3.66 3.70 5.32

CA780507 DH February 26, 1979  1:26 PM

3100	5	3100
3100	5	3100
3100	5	3100


************************

************************
Document:  CACM-2950.html
************************


A Unifying Approach to Scheduling

This paper presents a scheme for classifying
scheduling algorithms based on an abstract model 
of a scheduling system which formalizes the notion of
priority.  Various classes of scheduling algorithms
are defined and related to existing algorithms.  A
criterion for the implementation efficiency of an 
algorithm is developed and results in the definition
of time-invariant algorithms, which include most 
<B>of the</B> commonly implemented ones.  For time-invariant
algorithms, the dependence of processing rates 
on priorities is derived.  The abstract model provides
a framework for implementing flexible schedulers 
in real operating systems.  The policy-driven scheduler
of Bernstein and Sharp is discussed as an example 
of such an implementation

CACM July, 1977

Ruschitzka, M.
Fabry, R. S.

scheduling algorithms, scheduling models, priority,
operating systems,processor sharing, implementation 
efficiency

4.31 4.32 4.34 4.35 8.1

CA770702 JB December 28, 1977  12:32 PM

2950	4	2950
3072	4	2950
2219	5	2950
2950	5	2950
2950	5	2950
2950	5	2950


************************



A Unifying Approach to Scheduling

This paper presents a scheme for classifying
scheduling algorithms based on an abstract model 
of a scheduling system which formalizes the notion of
priority.  Various classes of scheduling algorithms
are defined and related to existing algorithms.  A
criterion <B>for the</B> implementation efficiency of an 
algorithm is developed and results in the definition
of time-invariant algorithms, which include most 
of the commonly implemented ones.  For time-invariant
algorithms, the dependence of processing rates 
on priorities is derived.  The abstract model provides
a framework for implementing flexible schedulers 
in real operating systems.  The policy-driven scheduler
of Bernstein and Sharp is discussed as an example 
of such an implementation

CACM July, 1977

Ruschitzka, M.
Fabry, R. S.

scheduling algorithms, scheduling models, priority,
operating systems,processor sharing, implementation 
efficiency

4.31 4.32 4.34 4.35 8.1

CA770702 JB December 28, 1977  12:32 PM

2950	4	2950
3072	4	2950
2219	5	2950
2950	5	2950
2950	5	2950
2950	5	2950


************************



A Unifying Approach to Scheduling

This paper presents a scheme for classifying
scheduling algorithms <B>based on</B> an abstract model 
of a scheduling system which formalizes the notion of
priority.  Various classes of scheduling algorithms
are defined and related to existing algorithms.  A
criterion for the implementation efficiency of an 
algorithm is developed and results in the definition
of time-invariant algorithms, which include most 
of the commonly implemented ones.  For time-invariant
algorithms, the dependence of processing rates 
on priorities is derived.  The abstract model provides
a framework for implementing flexible schedulers 
in real operating systems.  The policy-driven scheduler
of Bernstein and Sharp is discussed as an example 
of such an implementation

CACM July, 1977

Ruschitzka, M.
Fabry, R. S.

scheduling algorithms, scheduling models, priority,
operating systems,processor sharing, implementation 
efficiency

4.31 4.32 4.34 4.35 8.1

CA770702 JB December 28, 1977  12:32 PM

2950	4	2950
3072	4	2950
2219	5	2950
2950	5	2950
2950	5	2950
2950	5	2950


************************

************************
Document:  CACM-1905.html
************************


The Simplex Method of Linear Programming Using LU Decomposition

Standard computer implementations of Dantzig's
simplex method for linear programming <B>are based</B> 
upon forming the inverse of the basic matrix and updating
the inverse after every step of the method. 
 These implementations have bad round-off error properties.
 This paper gives the theoretical background 
for an implementation which is based upon the LU decomposition,
computed with row interchanges, of the 
basic matrix.  The implementation is slow, but has good
round-off error behavior.  The implementation 
appears as CACM Algorithm 350.

CACM May, 1969

Bartels, R. H.
Goulub, G. H.

simplex method, linear programming, LU decomposition,
round-off errors, computational stability

5.41

CA690504 JB February 17, 1978  3:49 PM

1905	4	1905
1744	5	1905
1905	5	1905
1905	5	1905
1905	5	1905


************************



The Simplex Method of Linear Programming Using LU Decomposition

Standard computer implementations of Dantzig's
simplex method for linear programming are based 
upon forming the inverse of the basic matrix and updating
the inverse after every step of the method. 
 These implementations have bad round-off error properties.
 This paper gives the theoretical background 
for an implementation which is based up<B>on the</B> LU decomposition,
computed with row interchanges, of the 
basic matrix.  The implementation is slow, but has good
round-off error behavior.  The implementation 
appears as CACM Algorithm 350.

CACM May, 1969

Bartels, R. H.
Goulub, G. H.

simplex method, linear programming, LU decomposition,
round-off errors, computational stability

5.41

CA690504 JB February 17, 1978  3:49 PM

1905	4	1905
1744	5	1905
1905	5	1905
1905	5	1905
1905	5	1905


************************



The Simplex Method of Linear Programming Using LU Decomposition

Standard computer implementations of Dantzig's
simplex method for linear programming are based 
upon forming the inverse <B>of the</B> basic matrix and updating
the inverse after every step of the method. 
 These implementations have bad round-off error properties.
 This paper gives the theoretical background 
for an implementation which is based upon the LU decomposition,
computed with row interchanges, of the 
basic matrix.  The implementation is slow, but has good
round-off error behavior.  The implementation 
appears as CACM Algorithm 350.

CACM May, 1969

Bartels, R. H.
Goulub, G. H.

simplex method, linear programming, LU decomposition,
round-off errors, computational stability

5.41

CA690504 JB February 17, 1978  3:49 PM

1905	4	1905
1744	5	1905
1905	5	1905
1905	5	1905
1905	5	1905


************************

************************
Document:  CACM-2701.html
************************


A Fast and Usually Linear Algorithm for Global
Flow Analysis (Abstract only--Complete paper JACM 
23,1 January, 1976)

A new algorithm for global flow analysis on
reducible graphs is presented. The algorithm is 
shown to treat a very general class of function spaces.
 For a graph of e edges, the algorithm has a 
worst case time bound of O(e log e) function operations.
 It is also shown that in programming terms, 
the number of operations is proportional to e plus the
number of exits from program loops.  Consequently 
a restriction to one-entry one-exit control structures
linearity.  The algorithm can be extended to yet 
larger classes of function spaces <B>and graph</B>s by relaxing
the time bound.  Examples are given of code 
improvement problems which can be solved using the algorithm.

CACM December, 1975

Graham, S. L.
Wegman, M.

global flow analysis, data flow, code optimization,
common subexpression elimination, live-dead 
analysis, information propagation, flow graph, reducibility,
go-to-less programming, depth-first search, 
path compression

4.12 5.24 5.25 5.32

CA751206 JB January 5, 1978  4:08 PM

2701	5	2701
2701	5	2701
2701	5	2701


************************

************************
Document:  CACM-1172.html
************************


Conversion of Limited-Entry Decision Tables to Computer Programs

Decision tables are useful for describing a
set of complex decision rules <B>based on</B> given sets 
of conditions.  Algorithms that can efficiently convert
the tables into computer programs will extend 
the usefulness of decision tables to computer users.
 Two such algorithms, based on work done by M. S. 
Montalbano, are described and extended here to handle
dashes and ELSE-decision rules.  The first algorithm 
minimizes the computer storage space required for the
resultant program, the second minimizes computer 
running time. During the conversion process, both pinpoint
any contradictions or redundancies among the 
rules in a table.

CACM November, 1965

Pollack, S. L.

CA651109 JB March 6, 1978  4:56 PM

1172	5	1172
1172	5	1172
1172	5	1172
1354	5	1172
2053	5	1172
2220	5	1172
2273	5	1172
2453	5	1172
2598	5	1172
2726	5	1172
2856	5	1172
1172	6	1172
1172	6	1172
1172	6	1172
1172	6	1172
1172	6	1172
1172	6	1172
1172	6	1172
1172	6	1172
1237	6	1172
1237	6	1172
1237	6	1172
1237	6	1172
1327	6	1172
1327	6	1172
1327	6	1172
1327	6	1172
1327	6	1172
1327	6	1172
1354	6	1172
1354	6	1172
1354	6	1172
1354	6	1172
1354	6	1172
1354	6	1172
1488	6	1172
1489	6	1172
1489	6	1172
1548	6	1172
1548	6	1172
1548	6	1172
1684	6	1172
250	6	1172
2053	6	1172
2053	6	1172
2053	6	1172
2220	6	1172
2220	6	1172
2220	6	1172
2220	6	1172
2220	6	1172
2221	6	1172
2263	6	1172
2263	6	1172
2453	6	1172
2453	6	1172
2598	6	1172
2691	6	1172
753	6	1172


************************



Conversion of Limited-Entry Decision Tables to Computer Programs

Decision tables are useful for describing a
set of complex decision rules based on given sets 
of conditions.  Algorithms that can efficiently convert
the tables into computer programs will extend 
the usefulness of decision tables to computer users.
 Two such algorithms, based on work done by M. S. 
Montalbano, are described and extended here to handle
dashes and ELSE-decision rules.  The first algorithm 
minimizes the computer storage space required <B>for the</B>
resultant program, the second minimizes computer 
running time. During the conversion process, both pinpoint
any contradictions or redundancies among the 
rules in a table.

CACM November, 1965

Pollack, S. L.

CA651109 JB March 6, 1978  4:56 PM

1172	5	1172
1172	5	1172
1172	5	1172
1354	5	1172
2053	5	1172
2220	5	1172
2273	5	1172
2453	5	1172
2598	5	1172
2726	5	1172
2856	5	1172
1172	6	1172
1172	6	1172
1172	6	1172
1172	6	1172
1172	6	1172
1172	6	1172
1172	6	1172
1172	6	1172
1237	6	1172
1237	6	1172
1237	6	1172
1237	6	1172
1327	6	1172
1327	6	1172
1327	6	1172
1327	6	1172
1327	6	1172
1327	6	1172
1354	6	1172
1354	6	1172
1354	6	1172
1354	6	1172
1354	6	1172
1354	6	1172
1488	6	1172
1489	6	1172
1489	6	1172
1548	6	1172
1548	6	1172
1548	6	1172
1684	6	1172
250	6	1172
2053	6	1172
2053	6	1172
2053	6	1172
2220	6	1172
2220	6	1172
2220	6	1172
2220	6	1172
2220	6	1172
2221	6	1172
2263	6	1172
2263	6	1172
2453	6	1172
2453	6	1172
2598	6	1172
2691	6	1172
753	6	1172


************************

************************
Document:  CACM-2275.html
************************


Integral Equations of Immunology

The inversion of a particular integral equation
of the first (Fredholm) kind is the basic problem 
considered.  The strategy which yielded success consisted
of three essential points: (1) fit the known 
experimental data by a curve with properties which derive
from properties of the (as yet unknown) function; 
(2) stabilize the computation for the unknown function
by using <B>singular value</B> decomposition; (3) constrain 
the unknown function approximation (since it represents
a probability distribution) to be nonnegative. 
 A number of test cases are presented. One set of actual
experimental data is analyzed with the procedures 
presented.

CACM October, 1972

Hanson, R. J.

integral equations of the first kind, nonnegative
constraints, singular value analysis

3.10 5.14 5.18 5.41

CA721003 JB January 27, 1978  3:37 PM

2275	5	2275
2275	5	2275
2275	5	2275


************************



Integral Equations of Immunology

The inversion of a particular integral equation
<B>of the</B> first (Fredholm) kind is the basic problem 
considered.  The strategy which yielded success consisted
of three essential points: (1) fit the known 
experimental data by a curve with properties which derive
from properties of the (as yet unknown) function; 
(2) stabilize the computation for the unknown function
by using singular value decomposition; (3) constrain 
the unknown function approximation (since it represents
a probability distribution) to be nonnegative. 
 A number of test cases are presented. One set of actual
experimental data is analyzed with the procedures 
presented.

CACM October, 1972

Hanson, R. J.

integral equations of the first kind, nonnegative
constraints, singular value analysis

3.10 5.14 5.18 5.41

CA721003 JB January 27, 1978  3:37 PM

2275	5	2275
2275	5	2275
2275	5	2275


************************



Integral Equations of Immunology

The inversion of a particular integral equation
of the first (Fredholm) kind is the basic problem 
considered.  The strategy which yielded success consisted
of three essential points: (1) fit the known 
experimental data by a curve with properties which derive
from properties of the (as yet unknown) function; 
(2) stabilize the computation <B>for the</B> unknown function
by using singular value decomposition; (3) constrain 
the unknown function approximation (since it represents
a probability distribution) to be nonnegative. 
 A number of test cases are presented. One set of actual
experimental data is analyzed with the procedures 
presented.

CACM October, 1972

Hanson, R. J.

integral equations of the first kind, nonnegative
constraints, singular value analysis

3.10 5.14 5.18 5.41

CA721003 JB January 27, 1978  3:37 PM

2275	5	2275
2275	5	2275
2275	5	2275


************************

************************
Document:  CACM-1878.html
************************


Recovery of Reentrant List Structures in SLIP

One consequence of the reference-count-based
space-recovery system employed by SLIP is that 
reentrant list structures are not recovered even when
explicitly erased.  LISP-like garbage-collection 
schemes are free of this impediment.  They however,
depend on being able <B>to find</B> and mark nodes that 
are reachable from program variables.  By tracing all
descendants from program variables may then be 
identified and collected.  The list-creating function
LIST of SLIP may be amended to mark those lists 
for which the programmer wishes to assume responsibility.
 Given this modification, a LISP-like garbage 
collector that recovers abandoned reentrant list structures
may then be appended to the SLIP system.

CACM July, 1969

Weizenbaum, J.

list processing, SLIP, garbage-collection

4.22 4.40

CA690702 JB February 17, 1978  9:39 AM

1024	4	1878
1024	4	1878
1051	4	1878
1051	4	1878
1098	4	1878
1102	4	1878
1132	4	1878
1214	4	1878
1380	4	1878
1388	4	1878
1390	4	1878
1393	4	1878
1485	4	1878
1486	4	1878
1487	4	1878
1549	4	1878
1549	4	1878
1570	4	1878
1706	4	1878
1826	4	1878
1878	4	1878
1878	4	1878
1946	4	1878
1957	4	1878
378	4	1878
2060	4	1878
2155	4	1878
2168	4	1878
2168	4	1878
2719	4	1878
2723	4	1878
2723	4	1878
2838	4	1878
2842	4	1878
2855	4	1878
2857	4	1878
2879	4	1878
3077	4	1878
3080	4	1878
3106	4	1878
3112	4	1878
627	4	1878
106	4	1878
210	5	1878
1878	5	1878
1878	5	1878
1878	5	1878
2023	5	1878
2168	5	1878
731	5	1878
106	6	1878
1626	6	1878
1826	6	1878
210	6	1878
1878	6	1878
1878	6	1878
731	6	1878


************************



Recovery of Reentrant List Structures in SLIP

One consequence <B>of the</B> reference-count-based
space-recovery system employed by SLIP is that 
reentrant list structures are not recovered even when
explicitly erased.  LISP-like garbage-collection 
schemes are free of this impediment.  They however,
depend on being able to find and mark nodes that 
are reachable from program variables.  By tracing all
descendants from program variables may then be 
identified and collected.  The list-creating function
LIST of SLIP may be amended to mark those lists 
for which the programmer wishes to assume responsibility.
 Given this modification, a LISP-like garbage 
collector that recovers abandoned reentrant list structures
may then be appended to the SLIP system.

CACM July, 1969

Weizenbaum, J.

list processing, SLIP, garbage-collection

4.22 4.40

CA690702 JB February 17, 1978  9:39 AM

1024	4	1878
1024	4	1878
1051	4	1878
1051	4	1878
1098	4	1878
1102	4	1878
1132	4	1878
1214	4	1878
1380	4	1878
1388	4	1878
1390	4	1878
1393	4	1878
1485	4	1878
1486	4	1878
1487	4	1878
1549	4	1878
1549	4	1878
1570	4	1878
1706	4	1878
1826	4	1878
1878	4	1878
1878	4	1878
1946	4	1878
1957	4	1878
378	4	1878
2060	4	1878
2155	4	1878
2168	4	1878
2168	4	1878
2719	4	1878
2723	4	1878
2723	4	1878
2838	4	1878
2842	4	1878
2855	4	1878
2857	4	1878
2879	4	1878
3077	4	1878
3080	4	1878
3106	4	1878
3112	4	1878
627	4	1878
106	4	1878
210	5	1878
1878	5	1878
1878	5	1878
1878	5	1878
2023	5	1878
2168	5	1878
731	5	1878
106	6	1878
1626	6	1878
1826	6	1878
210	6	1878
1878	6	1878
1878	6	1878
731	6	1878


************************

************************
Document:  CACM-2986.html
************************


Operations on Sparse Relations

Various computations on relations, Boolean matrices,
or directed graphs, such as the computation 
of precedence relations for a context-free grammar, can be
done by a practical algorithm that is asymptotically 
faster than those in common use.  For example, how to compute
operator precedence or Wirth-Weber precedence 
relations in O(n^2) steps is shown, as well as how to
compute linear precedence functions in O(n^2) steps 
is shown, as well as how to compute linear precedence
functions in O(n) steps, where n is the size of 
a grammer.  The heart <B>of the</B> algorithms is a general
theorem giving sufficient conditions under which 
an expression whose operands are sparse relations and
whose operators are composition, transitive closure, 
union, and inverse, can be computed efficiently.

CACM March, 1977

Hunt, H. B. III
Szymanski, T. G.
Ullman, J. D.

computational complexity, sparse relation, Boolean
matrix, directed graph, Wirth-Weber precedence 
relation, linear precedence function, SLR
grammar, T-canonical precedence relation

4.12 5.23 5.25

CA770306 JB December 29, 1977  8:05 AM

1542	4	2986
1683	4	2986
1693	4	2986
1781	4	2986
1787	4	2986
1836	4	2986
1945	4	2986
2060	4	2986
2061	4	2986
2082	4	2986
2091	4	2986
2152	4	2986
2179	4	2986
2221	4	2986
2340	4	2986
2340	4	2986
2340	4	2986
2356	4	2986
2546	4	2986
2603	4	2986
2698	4	2986
2708	4	2986
2733	4	2986
2824	4	2986
2824	4	2986
2824	4	2986
2982	4	2986
2982	4	2986
2982	4	2986
2986	4	2986
2986	4	2986
2986	4	2986
2986	4	2986
2986	4	2986
3045	4	2986
3093	4	2986
3093	4	2986
3094	4	2986
1491	5	2986
1683	5	2986
1836	5	2986
2179	5	2986
2340	5	2986
2986	5	2986
2986	5	2986
2986	5	2986


************************

************************
Document:  CACM-2619.html
************************


Graph Coloring Conditions for the Existence
of Solutions to the Timetable Problem

A necessary and sufficient condition is presented
for the existence of a solution to the Gotlieb 
class-teacher timetable problem.  Several relationships
are established between the class-teacher timetable 
problem <B>and graph</B>s with preconditions.  These preconditions
place additional restrictions on the coloration 
of a graph.  The preconditions correspond to the unavailability
constraints and preassigned meetings 
in the class-teacher timetable problem.  Using some recent
results that convert graphs with preconditions 
to graphs without them, it is shown that the existence
of a coloration of a graph is the required necessary 
and sufficient condition.

CACM August, 1974

Neufeld, G. A.
Tartar, J.

graphs, coloration, preassignment, prevention
of assignment, class-teacher timetables

3.9 5.30 5.32 5.59

CA740805 JB January 17, 1978  9:55 AM

1355	4	2619
2619	4	2619
2619	4	2619
2772	4	2619
2787	4	2619
1419	5	2619
1429	5	2619
2619	5	2619
2619	5	2619
2619	5	2619


************************



Graph Coloring Conditions for the Existence
of Solutions to the Timetable Problem

A necessary and sufficient condition is presented
for the existence of a solution to the Gotlieb 
class-teacher timetable problem.  Several relationships
are established between the class-teacher timetable 
problem and graphs with preconditions.  These preconditions
place additional restrictions <B>on the</B> coloration 
of a graph.  The preconditions correspond to the unavailability
constraints and preassigned meetings 
in the class-teacher timetable problem.  Using some recent
results that convert graphs with preconditions 
to graphs without them, it is shown that the existence
of a coloration of a graph is the required necessary 
and sufficient condition.

CACM August, 1974

Neufeld, G. A.
Tartar, J.

graphs, coloration, preassignment, prevention
of assignment, class-teacher timetables

3.9 5.30 5.32 5.59

CA740805 JB January 17, 1978  9:55 AM

1355	4	2619
2619	4	2619
2619	4	2619
2772	4	2619
2787	4	2619
1419	5	2619
1429	5	2619
2619	5	2619
2619	5	2619
2619	5	2619


************************



Graph Coloring Conditions <B>for the</B> Existence
of Solutions to the Timetable Problem

A necessary and sufficient condition is presented
for the existence of a solution to the Gotlieb 
class-teacher timetable problem.  Several relationships
are established between the class-teacher timetable 
problem and graphs with preconditions.  These preconditions
place additional restrictions on the coloration 
of a graph.  The preconditions correspond to the unavailability
constraints and preassigned meetings 
in the class-teacher timetable problem.  Using some recent
results that convert graphs with preconditions 
to graphs without them, it is shown that the existence
of a coloration of a graph is the required necessary 
and sufficient condition.

CACM August, 1974

Neufeld, G. A.
Tartar, J.

graphs, coloration, preassignment, prevention
of assignment, class-teacher timetables

3.9 5.30 5.32 5.59

CA740805 JB January 17, 1978  9:55 AM

1355	4	2619
2619	4	2619
2619	4	2619
2772	4	2619
2787	4	2619
1419	5	2619
1429	5	2619
2619	5	2619
2619	5	2619
2619	5	2619


************************

************************
Document:  CACM-2557.html
************************


On the Time Required for a Sequence of Matrix Products

This paper discusses the multiplication of conformable
sequences of row vectors, column vectors, 
and square matrices.  The minimum time required to evaluate
such products on ordinary serial computers 
as well as parallel computers is discussed.  Algorithms
are presented which properly parse such matrix 
sequences subject to the constraints <B>of the</B> machine organization.

CACM January, 1973

Muraoka, Y.
Kuck, D. J.

matrix expressions, matrix multiplication, operation
minimization, parallel machine, time minimization

4.22 5.14

CA730104 JB January 24, 1978  4:41 PM

1614	4	2557
2253	4	2557
2557	4	2557
2557	5	2557
2557	5	2557
2557	5	2557
437	5	2557
3075	5	2557
3085	5	2557
2289	6	2557
2557	6	2557
2557	6	2557
2664	6	2557
2714	6	2557


************************

************************
Document:  CACM-1961.html
************************


An Efficient Search Algorithm to Find the Elementary Circuits of a Graph

A theoretically most efficient search algorithm is presented
which uses an exhaustive search <B>to find</B> all of the elementary
circuits of a graph.  The algorithm can be easily modified to find all
of the elementary circuits with a particular attribute such as
length.  A rigorous proof of the algorithm is given as well as an example
of its application.  Empirical bounds are presented relating
the speed of the algorithm to the number of vertices and the number
of arcs.  The speed is also related to the number of circuits
in the graph to give a relation between speed and complexity.
Extensions to undirected and s-graphs are discussed.

CACM December, 1970

Tiernan, J. C.

algorithm, graph theory, circuit search
algorithm, path search algorithm, searching

3.74 5.32

CA701202 JB February 9, 1978 4:12 PM

1847	4	1961
1961	4	1961
1961	4	1961
1961	4	1961
2052	4	1961
2177	4	1961
2763	4	1961
1369	5	1961
1504	5	1961
1847	5	1961
1961	5	1961
1961	5	1961
1961	5	1961
2430	5	1961
1961	6	1961


************************



An Efficient Search Algorithm to Find the Elementary Circuits of a Graph

A theoretically most efficient search algorithm is presented
which uses an exhaustive search to find all <B>of the</B> elementary
circuits of a graph.  The algorithm can be easily modified to find all
of the elementary circuits with a particular attribute such as
length.  A rigorous proof of the algorithm is given as well as an example
of its application.  Empirical bounds are presented relating
the speed of the algorithm to the number of vertices and the number
of arcs.  The speed is also related to the number of circuits
in the graph to give a relation between speed and complexity.
Extensions to undirected and s-graphs are discussed.

CACM December, 1970

Tiernan, J. C.

algorithm, graph theory, circuit search
algorithm, path search algorithm, searching

3.74 5.32

CA701202 JB February 9, 1978 4:12 PM

1847	4	1961
1961	4	1961
1961	4	1961
1961	4	1961
2052	4	1961
2177	4	1961
2763	4	1961
1369	5	1961
1504	5	1961
1847	5	1961
1961	5	1961
1961	5	1961
1961	5	1961
2430	5	1961
1961	6	1961


************************

************************
Document:  CACM-2923.html
************************


High-Level Data Flow Analysis

In contrast to the predominant use of low-level
in termediate text, high-level data flow analysis 
deals with programs essentially at source level and
exploits the control flow information implicit in 
the parse tree.  The need for high-level flow analysis
arises from several aspects of recent work on 
advanced methods of program certification and optimization.
 This paper proposes a simple general method 
of high-level data flow analysis that allows free use
of escape and jump statements, avoids large graphs 
when compiling large programs, facilitates updating of
data flow information to reflect program changes, 
and derives new global information helpful in solving
many familiar global flow analysis problems.  An 
illustrative application to live variable analysis is presented.
 Many <B>of the</B> graphs involved are constructed 
and analyzed before any programs are compiled, thus avoiding
certain costs that low-level methods incur 
repeatedly at compile time.

CACM October, 1977

Rosen, B. K.

data flow analysis, high-level language, control
flow graph, structured programming, escapes, exits, 
jumps, goto statements

5.24 4.12 4.22

CA771003 JB December 27, 1977  11:41 AM

1807	4	2923
2034	4	2923
2290	4	2923
2579	4	2923
2579	4	2923
2923	4	2923
2923	4	2923
2945	4	2923
1807	5	2923
1947	5	2923
2923	5	2923
2923	5	2923
2923	5	2923


************************

************************
Document:  CACM-1411.html
************************


Comparison of Several Algorithms for Computation
of Means, Standard Deviations and Correlation 
Coefficients

Several <B>algorithms for</B> computation of basic
statistics are compared by their performance on 
systematically generated test data.  The statistics
calculated were the mean, standard deviation and 
correlation coefficient.  For each statistic, the algorithm
included the usual computing formulas, correction 
due to an accumulated error term, and a recursive computation
of the current value of the statistic. 
 The usual computing formulas were also evaluated in
double precision.  Large errors were noted for some 
calculation using the usual computing formulas.  The most
reliable technique was correction of the initial 
estimate by use of an accumulated error term.  To eliminate
the need for making two passes on the data, 
it was suggested that the initial estimate of the
mean be obtained from a subset of the data.

CACM July, 1966

Neely, P. M.

CA660703 JB March 6, 1978  2:54 PM

1411	5	1411
1411	5	1411
1411	5	1411
1619	5	1411
3166	5	1411
1411	6	1411
1411	6	1411
2731	6	1411
2799	6	1411
3159	6	1411
3167	6	1411


************************



Comparison of Several Algorithms for Computation
of Means, Standard Deviations and Correlation 
Coefficients

Several algorithms for computation of basic
statistics are compared by their performance on 
systematically generated test data.  The statistics
calculated were the mean, standard deviation and 
correlation coefficient.  For each statistic, the algorithm
included the usual computing formulas, correction 
due to an accumulated error term, and a recursive computation
of the current value of the statistic. 
 The usual computing formulas were also evaluated in
double precision.  Large errors were noted for some 
calculation using the usual computing formulas.  The most
reliable technique was correction of the initial 
estimate by use of an accumulated error term.  To eliminate
the need for making two passes <B>on the</B> data, 
it was suggested that the initial estimate of the
mean be obtained from a subset of the data.

CACM July, 1966

Neely, P. M.

CA660703 JB March 6, 1978  2:54 PM

1411	5	1411
1411	5	1411
1411	5	1411
1619	5	1411
3166	5	1411
1411	6	1411
1411	6	1411
2731	6	1411
2799	6	1411
3159	6	1411
3167	6	1411


************************



Comparison of Several Algorithms for Computation
of Means, Standard Deviations and Correlation 
Coefficients

Several algorithms for computation of basic
statistics are compared by their performance on 
systematically generated test data.  The statistics
calculated were the mean, standard deviation and 
correlation coefficient.  For each statistic, the algorithm
included the usual computing formulas, correction 
due to an accumulated error term, and a recursive computation
<B>of the</B> current value of the statistic. 
 The usual computing formulas were also evaluated in
double precision.  Large errors were noted for some 
calculation using the usual computing formulas.  The most
reliable technique was correction of the initial 
estimate by use of an accumulated error term.  To eliminate
the need for making two passes on the data, 
it was suggested that the initial estimate of the
mean be obtained from a subset of the data.

CACM July, 1966

Neely, P. M.

CA660703 JB March 6, 1978  2:54 PM

1411	5	1411
1411	5	1411
1411	5	1411
1619	5	1411
3166	5	1411
1411	6	1411
1411	6	1411
2731	6	1411
2799	6	1411
3159	6	1411
3167	6	1411


************************

************************
Document:  CACM-2177.html
************************


An Algorithm for the Blocks and Cutnodes of a Graph

An efficient method is presented for finding
blocks and cutnodes of an arbitrary undirected 
graph.  The graph may be represented either (i) as an
ordered list of edges or (ii) as a packed adjacency 
matrix.  If w denotes the word length <B>of the</B> machine
employed, the storage (in machine words) required 
for a graph with n nodes and m edges increases essentially
as 2(m+n) in case (i), or (n^2)/win case 
(ii).  A spanning tree with labeled edges is grown,
two edges finally bearing different labels if and 
only if they belong to different blocks.  For both representations
the time required to analyze a graph 
on n nodes increases as n^G where G depends on the type
of graph, 1 <= G <= 2, and both bounds are attained. 
 Values of G are derived for each of several suitable
families of test graphs, generated by an extension 
of the web grammar approach.  The algorithm is compared
in detail with that proposed by Read for which 
1 <= G <= 3.

CACM July, 1971

Paton, K.

algorithm, block, block-cutpoint-tree, cutnode, fundamental
cycle set, graph, lobe, lobe decomposition 
graph, separable, spanning tree, web grammar

5.32

CA710705 JB February 3, 1978  8:58 AM

1961	4	2177
2177	4	2177
2763	4	2177
1847	5	2177
2177	5	2177
2177	5	2177
2177	5	2177
2490	5	2177
2177	6	2177


************************



An Algorithm <B>for the</B> Blocks and Cutnodes of a Graph

An efficient method is presented for finding
blocks and cutnodes of an arbitrary undirected 
graph.  The graph may be represented either (i) as an
ordered list of edges or (ii) as a packed adjacency 
matrix.  If w denotes the word length of the machine
employed, the storage (in machine words) required 
for a graph with n nodes and m edges increases essentially
as 2(m+n) in case (i), or (n^2)/win case 
(ii).  A spanning tree with labeled edges is grown,
two edges finally bearing different labels if and 
only if they belong to different blocks.  For both representations
the time required to analyze a graph 
on n nodes increases as n^G where G depends on the type
of graph, 1 <= G <= 2, and both bounds are attained. 
 Values of G are derived for each of several suitable
families of test graphs, generated by an extension 
of the web grammar approach.  The algorithm is compared
in detail with that proposed by Read for which 
1 <= G <= 3.

CACM July, 1971

Paton, K.

algorithm, block, block-cutpoint-tree, cutnode, fundamental
cycle set, graph, lobe, lobe decomposition 
graph, separable, spanning tree, web grammar

5.32

CA710705 JB February 3, 1978  8:58 AM

1961	4	2177
2177	4	2177
2763	4	2177
1847	5	2177
2177	5	2177
2177	5	2177
2177	5	2177
2490	5	2177
2177	6	2177


************************



An Algorithm for the Blocks and Cutnodes of a Graph

An efficient method is presented for finding
blocks and cutnodes of an arbitrary undirected 
graph.  The graph may be represented either (i) as an
ordered list of edges or (ii) as a packed adjacency 
matrix.  If w denotes the word length of the machine
employed, the storage (in machine words) required 
for a graph with n nodes and m edges increases essentially
as 2(m+n) in case (i), or (n^2)/win case 
(ii).  A spanning tree with labeled edges is grown,
two edges finally bearing different labels if and 
only if they belong to different blocks.  For both representations
the time required to analyze a graph 
on n nodes increases as n^G where G depends <B>on the</B> type
of graph, 1 <= G <= 2, and both bounds are attained. 
 Values of G are derived for each of several suitable
families of test graphs, generated by an extension 
of the web grammar approach.  The algorithm is compared
in detail with that proposed by Read for which 
1 <= G <= 3.

CACM July, 1971

Paton, K.

algorithm, block, block-cutpoint-tree, cutnode, fundamental
cycle set, graph, lobe, lobe decomposition 
graph, separable, spanning tree, web grammar

5.32

CA710705 JB February 3, 1978  8:58 AM

1961	4	2177
2177	4	2177
2763	4	2177
1847	5	2177
2177	5	2177
2177	5	2177
2177	5	2177
2490	5	2177
2177	6	2177


************************

************************
Document:  CACM-2767.html
************************


A Comparison of Simulation Event List Algorithms

Four algorithms are considered which can be used
to schedule events in a general purpose discrete 
simulation system.  Two of the algorithms are new, one
is based on an end-order tree structure for event 
notices, and another uses an indexed linear list. The algorithms
are tested with a set of typical stochastic 
scheduling distributions especially chosen to show
the advantages and limitations of the algorithms. 
 The end-order tree algorithm is shown to be an advantageous,
immediate replacement <B>for the</B> algorithm 
in use with current simulation languages.  The most
promising algorithm uses the indexed list concept. 
 It will require an adaptive routine before it can
be employed in general purpose simulators,but its 
performance is such that further study would be fruitful.

CACM April, 1975

Vaucher, J. G.
Duval, P.

simulation, time flow mechanisms, event list algorithm,
simulation, time flow mechanisms, event 
list algorithm, simulation executive, event scheduling
routine, discrete system simulation, sorting

3.74 4.22 8.1

CA750410 JB January 9, 1978  3:43 PM

2767	4	2767
3064	4	2767
1939	5	2767
2767	5	2767
2767	5	2767
2767	5	2767
2844	5	2767
2936	5	2767
3051	5	2767
3064	5	2767
3109	5	2767
970	6	2767
1059	6	2767
1846	6	2767
1939	6	2767
2742	6	2767
2742	6	2767
2742	6	2767
2767	6	2767
2767	6	2767
2767	6	2767
2767	6	2767
2767	6	2767
2844	6	2767
2844	6	2767
2936	6	2767


************************



A Comparison of Simulation Event List Algorithms

Four algorithms are considered which can be used
to schedule events in a general purpose discrete 
simulation system.  Two of the algorithms are new, one
is <B>based on</B> an end-order tree structure for event 
notices, and another uses an indexed linear list. The algorithms
are tested with a set of typical stochastic 
scheduling distributions especially chosen to show
the advantages and limitations of the algorithms. 
 The end-order tree algorithm is shown to be an advantageous,
immediate replacement for the algorithm 
in use with current simulation languages.  The most
promising algorithm uses the indexed list concept. 
 It will require an adaptive routine before it can
be employed in general purpose simulators,but its 
performance is such that further study would be fruitful.

CACM April, 1975

Vaucher, J. G.
Duval, P.

simulation, time flow mechanisms, event list algorithm,
simulation, time flow mechanisms, event 
list algorithm, simulation executive, event scheduling
routine, discrete system simulation, sorting

3.74 4.22 8.1

CA750410 JB January 9, 1978  3:43 PM

2767	4	2767
3064	4	2767
1939	5	2767
2767	5	2767
2767	5	2767
2767	5	2767
2844	5	2767
2936	5	2767
3051	5	2767
3064	5	2767
3109	5	2767
970	6	2767
1059	6	2767
1846	6	2767
1939	6	2767
2742	6	2767
2742	6	2767
2742	6	2767
2767	6	2767
2767	6	2767
2767	6	2767
2767	6	2767
2767	6	2767
2844	6	2767
2844	6	2767
2936	6	2767


************************



A Comparison of Simulation Event List Algorithms

Four algorithms are considered which can be used
to schedule events in a general purpose discrete 
simulation system.  Two <B>of the</B> algorithms are new, one
is based on an end-order tree structure for event 
notices, and another uses an indexed linear list. The algorithms
are tested with a set of typical stochastic 
scheduling distributions especially chosen to show
the advantages and limitations of the algorithms. 
 The end-order tree algorithm is shown to be an advantageous,
immediate replacement for the algorithm 
in use with current simulation languages.  The most
promising algorithm uses the indexed list concept. 
 It will require an adaptive routine before it can
be employed in general purpose simulators,but its 
performance is such that further study would be fruitful.

CACM April, 1975

Vaucher, J. G.
Duval, P.

simulation, time flow mechanisms, event list algorithm,
simulation, time flow mechanisms, event 
list algorithm, simulation executive, event scheduling
routine, discrete system simulation, sorting

3.74 4.22 8.1

CA750410 JB January 9, 1978  3:43 PM

2767	4	2767
3064	4	2767
1939	5	2767
2767	5	2767
2767	5	2767
2767	5	2767
2844	5	2767
2936	5	2767
3051	5	2767
3064	5	2767
3109	5	2767
970	6	2767
1059	6	2767
1846	6	2767
1939	6	2767
2742	6	2767
2742	6	2767
2742	6	2767
2767	6	2767
2767	6	2767
2767	6	2767
2767	6	2767
2767	6	2767
2844	6	2767
2844	6	2767
2936	6	2767


************************

************************
Document:  CACM-2195.html
************************


On the Optimal Detection of Curves in Noisy Pictures

A technique for recognizing systems of lines
is presented.  In this technique the heuristic 
<B>of the</B> problem is not embedded in the recognition algorithm
but is expressed in a figure of merit.   
A multistage decision process is then able to recognize
in the input picture the optimal system of lines 
according to the given figure of merit.  Due to the
global approach, greater flexibility and adequacy 
in the particular problem is achieved.  The relation
between the structure of the figure of merit and 
the complexity of the optimization process is then discussed.
 The method described is suitable for parallel 
processing because the operations relative to each
state can be computed in parallel, and the number
of stages is equal to the length N of the curves (or
to log2 N if the approximate method is used).

CACM May, 1971

Montanari, U.

picture processing, picture recognition, picture
description, curve detection, line detection, 
edge detection,optimal detection, heuristic methods,
global recognition, parallel processing, dynamic 
programming, interaction graph, secondary optimization problem

3.63 3.66 5.42

CA710504 JB February 3, 1978  2:49 PM

1663	4	2195
2195	4	2195
2679	4	2195
1190	5	2195
2195	5	2195
2195	5	2195
2195	5	2195
2883	5	2195
2195	6	2195


************************

************************
Document:  CACM-2484.html
************************


A Note on Information Organization and Storage

Since the logical structure of a data base
can be represented by a tree or graph, it is quite 
natural for us to view the process of designing a data
base as that of constructing a tree or a graph. 
 A general method for constructing such a tree or a graph
is provided.  There are three important elements 
in this general construction method; namely, a set of
binary relations, an algorithm for constructing 
subsets of a set, and an algorithm for selecting an
element from the given set of objects.  The use of 
different relations and algorithms results in different
information structures, as list, tree, ring, 
etc.  Thus the problem of information organization and
storage is reduced to that of defining relations 
and formulating algorithms under a given set of constraints.
 The results presented may be valuable to 
designers as useful design concepts, and may serve as
a basis for developing a formal theory <B>on the</B> subject.

CACM July, 1973

Huang, J. C.

data base, data-base management, information retrieval,
information structure, file organization, 
storage allocation, tree, graph

3.70 3.73 3.74 5.32

CA730702 JB January 23, 1978  1:14 PM

2484	5	2484
2484	5	2484
2484	5	2484


************************

************************
Document:  CACM-2155.html
************************


Toward an Understanding of Data Structures

This paper presents a notation and formalism
for describing the semantics of data structures. 
 This is <B>based on</B> directed graphs with named edges and
transformations on these graphs.  In addition, 
an implementation facility is described which could
be part of a programming language, which allows a 
programmer who has expressed the semantics of an algorithm
in terms of the graphs to then specify the 
implementation of some of his data structures in order to gain efficiency.

CACM October,1971

Earley, J.

data structures, graph, implementation,
semantic formalism, programming language

4.22 4.9 5.24

CA711001 JB February 2, 1978  1:35 PM

1024	4	2155
1051	4	2155
1051	4	2155
1102	4	2155
1132	4	2155
1390	4	2155
1486	4	2155
1549	4	2155
1552	4	2155
1665	4	2155
1706	4	2155
1826	4	2155
1860	4	2155
1860	4	2155
1878	4	2155
1957	4	2155
378	4	2155
2060	4	2155
2155	4	2155
2155	4	2155
2155	4	2155
2155	4	2155
2155	4	2155
2162	4	2155
2168	4	2155
2294	4	2155
2406	4	2155
2558	4	2155
2710	4	2155
2715	4	2155
2716	4	2155
2717	4	2155
2718	4	2155
2719	4	2155
2723	4	2155
2765	4	2155
2817	4	2155
2838	4	2155
2842	4	2155
2842	4	2155
2855	4	2155
2879	4	2155
2888	4	2155
2901	4	2155
2957	4	2155
2959	4	2155
2965	4	2155
3077	4	2155
3077	4	2155
3080	4	2155
3087	4	2155
3106	4	2155
3150	4	2155
3154	4	2155
627	4	2155
106	4	2155
210	5	2155
1389	5	2155
378	5	2155
2046	5	2155
2060	5	2155
2155	5	2155
2155	5	2155
2155	5	2155
2252	5	2155
2594	5	2155
1358	6	2155
1496	6	2155
1771	6	2155
2155	6	2155
2155	6	2155
2204	6	2155
3184	6	2155
3186	6	2155


************************



Toward an Understanding of Data Structures

This paper presents a notation and formalism
for describing the semantics of data structures. 
 This is based on directed graphs with named edges and
transformations on these graphs.  In addition, 
an implementation facility is described which could
be part of a programming language, which allows a 
programmer who has expressed the semantics of an algorithm
in terms <B>of the</B> graphs to then specify the 
implementation of some of his data structures in order to gain efficiency.

CACM October,1971

Earley, J.

data structures, graph, implementation,
semantic formalism, programming language

4.22 4.9 5.24

CA711001 JB February 2, 1978  1:35 PM

1024	4	2155
1051	4	2155
1051	4	2155
1102	4	2155
1132	4	2155
1390	4	2155
1486	4	2155
1549	4	2155
1552	4	2155
1665	4	2155
1706	4	2155
1826	4	2155
1860	4	2155
1860	4	2155
1878	4	2155
1957	4	2155
378	4	2155
2060	4	2155
2155	4	2155
2155	4	2155
2155	4	2155
2155	4	2155
2155	4	2155
2162	4	2155
2168	4	2155
2294	4	2155
2406	4	2155
2558	4	2155
2710	4	2155
2715	4	2155
2716	4	2155
2717	4	2155
2718	4	2155
2719	4	2155
2723	4	2155
2765	4	2155
2817	4	2155
2838	4	2155
2842	4	2155
2842	4	2155
2855	4	2155
2879	4	2155
2888	4	2155
2901	4	2155
2957	4	2155
2959	4	2155
2965	4	2155
3077	4	2155
3077	4	2155
3080	4	2155
3087	4	2155
3106	4	2155
3150	4	2155
3154	4	2155
627	4	2155
106	4	2155
210	5	2155
1389	5	2155
378	5	2155
2046	5	2155
2060	5	2155
2155	5	2155
2155	5	2155
2155	5	2155
2252	5	2155
2594	5	2155
1358	6	2155
1496	6	2155
1771	6	2155
2155	6	2155
2155	6	2155
2204	6	2155
3184	6	2155
3186	6	2155


************************



Toward an Understanding of Data Structures

This paper presents a notation and formalism
for describing the semantics of data structures. 
 This is based on directed graphs with named edges and
transformations <B>on the</B>se graphs.  In addition, 
an implementation facility is described which could
be part of a programming language, which allows a 
programmer who has expressed the semantics of an algorithm
in terms of the graphs to then specify the 
implementation of some of his data structures in order to gain efficiency.

CACM October,1971

Earley, J.

data structures, graph, implementation,
semantic formalism, programming language

4.22 4.9 5.24

CA711001 JB February 2, 1978  1:35 PM

1024	4	2155
1051	4	2155
1051	4	2155
1102	4	2155
1132	4	2155
1390	4	2155
1486	4	2155
1549	4	2155
1552	4	2155
1665	4	2155
1706	4	2155
1826	4	2155
1860	4	2155
1860	4	2155
1878	4	2155
1957	4	2155
378	4	2155
2060	4	2155
2155	4	2155
2155	4	2155
2155	4	2155
2155	4	2155
2155	4	2155
2162	4	2155
2168	4	2155
2294	4	2155
2406	4	2155
2558	4	2155
2710	4	2155
2715	4	2155
2716	4	2155
2717	4	2155
2718	4	2155
2719	4	2155
2723	4	2155
2765	4	2155
2817	4	2155
2838	4	2155
2842	4	2155
2842	4	2155
2855	4	2155
2879	4	2155
2888	4	2155
2901	4	2155
2957	4	2155
2959	4	2155
2965	4	2155
3077	4	2155
3077	4	2155
3080	4	2155
3087	4	2155
3106	4	2155
3150	4	2155
3154	4	2155
627	4	2155
106	4	2155
210	5	2155
1389	5	2155
378	5	2155
2046	5	2155
2060	5	2155
2155	5	2155
2155	5	2155
2155	5	2155
2252	5	2155
2594	5	2155
1358	6	2155
1496	6	2155
1771	6	2155
2155	6	2155
2155	6	2155
2204	6	2155
3184	6	2155
3186	6	2155


************************

************************
Document:  CACM-2408.html
************************


Solving the Biharmonic Equation in a Square:
A Direct Versus a Semidirect Method

Two methods for solving the biharmonic equation
are compared.  One method is direct, using 
eigenvalue-eigenvector decomposition.  The other method
is iterative, solving a Poisson equation directly 
at each iteration.

CACM November, 1973

Ehrlich, L. W.

biharmonic, direct method, block iterative,
eigenvector-<B>eigenvalue decomposition</B>

5.14 5.17

CA731118 JB January 19, 1978  3:28 PM

2408	5	2408
2408	5	2408
2408	5	2408


************************

************************
Document:  CACM-1159.html
************************


Machine Independence: Its Technology and Economics

A survey is offered of techniques for transferring
programs, and especially compilers, from 
one computer to another.  Of the methods examined, the
"bootstrap" technique is singled out for detailed 
discussion, with emphasis on its economics. The considerations
that determine the applicability of bootstrapping 
<B>in any</B> specific case are discussed, and an attempt
is made to assign appropriate qualitative weights 
to them.  Finally, reasons are given for believing that the
machine-independence problem is being substantially 
diminished by current trends in computer design, and
that it is this process of convergence in hardware 
design rather than any foreseeable software developments
that will lead to its satisfactory resolution.

CACM December, 1965

Halpern, M. I.

CA651210 JB March 6, 1978  3:44 PM

1159	4	1159
1988	4	1159
381	4	1159
1159	5	1159
1159	5	1159
1159	5	1159
14	5	1159


************************

************************
Document:  CACM-2697.html
************************


A Fast Method for Solving a Class of Tridiagonal Linear Systems

The solution of linear systems having real, symmetric,
diagonally dominant,tridiagonal coefficient 
matrices with constant diagonals is considered.  It is
proved that the diagonals <B>of the</B> LU decomposition 
converges when floating-point precision.  It is also
proved that the computed LU decomposition converges 
when floating-point arithmetic is used and that the limits
of the LU diagonals using floating point are 
roughly within machine precision of the limits using
real arithmetic.  This fact is exploited to reduce 
the number of floating-point operations required to
solve a linear system from 8n-7 to 5n+2k-3, where 
k is much less than n, the order of the matrix.  If the
elements of the subdiagonals and superdiagonals 
are 1, then only 4n+2k-3 operations are needed.  The
entire LU decomposition takes k words of storage, 
and considerable savings in array subscripting are achieved.
 Upper and lower bounds on k are obtained 
in terms of the ratio of the coefficient matrix diagonal
constants and parameters of the floating-point 
number system.  Various generalizations of these results are discussed.

CACM January, 1974

Malcolm, M. A.
Palmer, J.

numerical linear algebra, linear systems,
Toeplitz matrices, tridiagonal matrices

5 5.1 5.11 5.14 5.17

CA740102 JB January 18, 1978  2:50 PM

2697	5	2697
2697	5	2697
2697	5	2697


************************

************************
Document:  CACM-1145.html
************************


GIT-A Heuristic Program for Testing Pairs
of Directed Line Graphs for Isomorphism*

Given a pair of directed line graphs, the problem
of ascertaining whether or not they are isomorphic 
is one for which no efficient algorithmic solution is known.
 Since a straightforward enumerative algorithm 
might require 40 years of running time on a very high
speed computer in order to compare two 15-node 
graphs, a more sophisticated approach seems called
for.  The situation is similar to that prevailing 
in areas such as game-playing and theorem-proving, where
practical algorithms are unknown (for the interesting 
cases), but where various practical though only partially
successful techniques are available.  Git-Graph 
Isomorphism Tester-incorporates a variety of processes
that attempt to narrow down the search for an 
isomorphism, or to demonstrate that none exists.  No one
scheme is relied upon exclusively for a solution, 
and the program is designed to avoid excessive computation
along fruitless lines.  GIT has been written 
in the COMIT language and successfully tested <B>on the</B> IBM 7090.

CACM January, 1964

Unger, S. H.

CA640110 JB March 10, 1978  5:24 AM

1145	4	1145
1145	5	1145
1145	5	1145
1145	5	1145
1504	5	1145
3040	5	1145
655	5	1145
1145	6	1145
1145	6	1145


************************



GIT-A Heuristic Program for Testing Pairs
of Directed Line Graphs for Isomorphism*

Given a pair of directed line graphs, the problem
of ascertaining whether or not they are isomorphic 
is one for which no efficient algorithmic solution is known.
 Since a straightforward enumerative algorithm 
might require 40 years of running time on a very high
speed computer in order to compare two 15-node 
graphs, a more sophisticated approach seems called
for.  The situation is similar to that prevailing 
in areas such as game-playing and theorem-proving, where
practical algorithms are unknown (<B>for the</B> interesting 
cases), but where various practical though only partially
successful techniques are available.  Git-Graph 
Isomorphism Tester-incorporates a variety of processes
that attempt to narrow down the search for an 
isomorphism, or to demonstrate that none exists.  No one
scheme is relied upon exclusively for a solution, 
and the program is designed to avoid excessive computation
along fruitless lines.  GIT has been written 
in the COMIT language and successfully tested on the IBM 7090.

CACM January, 1964

Unger, S. H.

CA640110 JB March 10, 1978  5:24 AM

1145	4	1145
1145	5	1145
1145	5	1145
1145	5	1145
1504	5	1145
3040	5	1145
655	5	1145
1145	6	1145
1145	6	1145


************************

************************
Document:  CACM-2554.html
************************


Reduction of a Band-Symmetric Generalized Eigenvalue Problem

An algorithm is described for reducing the
generalized eigenvalue problem Ax = lambda Bx to 
an ordinary problem, in case A and B are symmetric band
matrices with B positive definite.  If n is the 
order <B>of the</B> matrix and m the bandwidth, the matrices
A and B are partitioned into m-by-m blocks; and 
the algorithm is described in terms of these blocks.
 The algorithm reduces the generalized problem to 
an ordinary eigenvalue problem for a symmetric band
matrix C whose bandwidth is the same as A and B. 
 The algorithm is similar to those of Rutishauser and
Schwartz for the reduction of symmetric matrices 
to band form.  The calculation C requires order mn^2
operation.  The round-off error in the calculation 
of C is of the same order as the sum of the errors at
each of the n/m steps of the algorithm, the latter 
errors being largely determined by the condition of B with respect to inversion.

CACM January, 1973

Crawford, C. R.

generalized eigenvalues, symmetric band matrices

5.14

CA730107 JB January 24, 1978  4:26 PM

2554	5	2554
2554	5	2554
2554	5	2554


************************



Reduction of a Band-Symmetric Generalized Eigenvalue Problem

An algorithm is described for reducing the
generalized eigenvalue problem Ax = lambda Bx to 
an ordinary problem, in case A and B are symmetric band
matrices with B positive definite.  If n is the 
order of the matrix and m the bandwidth, the matrices
A and B are partitioned into m-by-m blocks; and 
the algorithm is described in terms of these blocks.
 The algorithm reduces the generalized problem to 
an ordinary eigenvalue problem for a symmetric band
matrix C whose bandwidth is the same as A and B. 
 The algorithm is similar to those of Rutishauser and
Schwartz <B>for the</B> reduction of symmetric matrices 
to band form.  The calculation C requires order mn^2
operation.  The round-off error in the calculation 
of C is of the same order as the sum of the errors at
each of the n/m steps of the algorithm, the latter 
errors being largely determined by the condition of B with respect to inversion.

CACM January, 1973

Crawford, C. R.

generalized eigenvalues, symmetric band matrices

5.14

CA730107 JB January 24, 1978  4:26 PM

2554	5	2554
2554	5	2554
2554	5	2554


************************

************************
Document:  CACM-1423.html
************************


A Simple Algorithm for Computing the Generalized Inverse of a Matrix

The generalized inverse of a matrix is important
in analysis because it provides an extension 
<B>of the</B> concept of an inverse which applies to all matrices.
 It also has many applications in numerical 
analysis, but it is not widely used because the existing
algorithms are fairly complicated and require 
considerable storage space.  A simple extension has
been found to the conventional orthogonalization 
method for inverting non-singular matrices, which gives
the generalized inverse with little extra effort 
and with no additional storage requirements.  The algorithm
gives the generalized inverse for any m by 
n matrix A, including the special case when m+n and A
is non-singular and the case when m>n and rank(A) 
= n.  In the first case the algorithm gives the ordinary
inverse of A.  In the second case the algorithm 
yields the ordinary least squares transformation matrix
INV(A'A)A' and has the advantage of avoiding 
the loss of significance which results in forming the product A'A explicitly.

CACM May, 1966

Rust, R.
Burrus, W. R.
Schneeberger, C.

CA660514 JB March 3, 1978  9:22 AM

1423	5	1423
1423	5	1423
1423	5	1423


************************

************************
Document:  CACM-2289.html
************************


Cellular Arrays for the Solution of Graph Problems

A cellular array is a two-dimensional, checkerboard
type interconnection of identical modules 
(or cells), where each cell contains a few bits of
memory and a small amount of combinational logic, 
and communicates mainly with its immediate neighbors
in the array.  The chief computational advantage 
offered by cellular arrays is the improvement in speed
achieved by virtue <B>of the</B> possibilities for parallel 
processing.  In this paper it is shown that cellular
arrays are inherently well suited for the solution 
of many graph problems.  For example, the adjacency
matrix of a graph is easily mapped onto an array; 
each matrix element is stored in one cell of the array,
and typical row and column operations are readily 
implemented by simple cell logic.  A major challenge
in the effective use of cellular arrays for the 
solution of graph problems is the determination of algorithms
that exploit the possibilities for parallelism, 
especially for problems whose solutions appear to be inherently
serial.  In particular, several parallelized 
algorithms are presented for the solution of certain
spanning tree, distance, and path problems, with 
direct applications to wire routing, PERT chart analysis,
and the analysis of many types of networks. 
 These algorithms exhibit a computation time that in
many cases grows at a rate not exceeding log2 n, 
where n is the number of nodes in the graph.  Straightforward
cellular implementations of the well-known 
serial algorithms for these problems require about n
steps, and noncellular implementations require from 
n^2 to n^3 steps.

CACM September, 1972

Levitt, K. N.
Kautz, W. H.

graph theory, cellular logic-in-memory arrays,
parallel processing, special purpose computers, 
algorithms for distance and spanning tree problems

5.32 6.22 6.5

CA720901 JB January 30, 1978  9:16 AM

2289	5	2289
2289	5	2289
2289	5	2289
3075	5	2289
3156	5	2289
2289	6	2289
2289	6	2289
2557	6	2289
2664	6	2289
2714	6	2289
2973	6	2289
3075	6	2289


************************



Cellular Arrays <B>for the</B> Solution of Graph Problems

A cellular array is a two-dimensional, checkerboard
type interconnection of identical modules 
(or cells), where each cell contains a few bits of
memory and a small amount of combinational logic, 
and communicates mainly with its immediate neighbors
in the array.  The chief computational advantage 
offered by cellular arrays is the improvement in speed
achieved by virtue of the possibilities for parallel 
processing.  In this paper it is shown that cellular
arrays are inherently well suited for the solution 
of many graph problems.  For example, the adjacency
matrix of a graph is easily mapped onto an array; 
each matrix element is stored in one cell of the array,
and typical row and column operations are readily 
implemented by simple cell logic.  A major challenge
in the effective use of cellular arrays for the 
solution of graph problems is the determination of algorithms
that exploit the possibilities for parallelism, 
especially for problems whose solutions appear to be inherently
serial.  In particular, several parallelized 
algorithms are presented for the solution of certain
spanning tree, distance, and path problems, with 
direct applications to wire routing, PERT chart analysis,
and the analysis of many types of networks. 
 These algorithms exhibit a computation time that in
many cases grows at a rate not exceeding log2 n, 
where n is the number of nodes in the graph.  Straightforward
cellular implementations of the well-known 
serial algorithms for these problems require about n
steps, and noncellular implementations require from 
n^2 to n^3 steps.

CACM September, 1972

Levitt, K. N.
Kautz, W. H.

graph theory, cellular logic-in-memory arrays,
parallel processing, special purpose computers, 
algorithms for distance and spanning tree problems

5.32 6.22 6.5

CA720901 JB January 30, 1978  9:16 AM

2289	5	2289
2289	5	2289
2289	5	2289
3075	5	2289
3156	5	2289
2289	6	2289
2289	6	2289
2557	6	2289
2664	6	2289
2714	6	2289
2973	6	2289
3075	6	2289


************************



Cellular Arrays for the Solution of Graph Problems

A cellular array is a two-dimensional, checkerboard
type interconnection of identical modules 
(or cells), where each cell contains a few bits of
memory and a small amount of combinational logic, 
and communicates mainly with its immediate neighbors
in the array.  The chief computational advantage 
offered by cellular arrays is the improvement in speed
achieved by virtue of the possibilities for parallel 
processing.  In this paper it is shown that cellular
arrays are inherently well suited for the solution 
of many graph problems.  For example, the adjacency
matrix of a graph is easily mapped onto an array; 
each matrix element is stored in one cell of the array,
and typical row and column operations are readily 
implemented by simple cell logic.  A major challenge
in the effective use of cellular arrays for the 
solution of graph problems is the determination of algorithms
that exploit the possibilities for parallelism, 
especially for problems whose solutions appear to be inherently
serial.  In particular, several parallelized 
algorithms are presented for the solution of certain
spanning tree, distance, and path problems, with 
direct applications to wire routing, PERT chart analysis,
and the analysis of many types of networks. 
 These algorithms exhibit a computation time that in
many cases grows at a rate not exceeding log2 n, 
where n is the number of nodes in <B>the graph.</B>  Straightforward
cellular implementations of the well-known 
serial algorithms for these problems require about n
steps, and noncellular implementations require from 
n^2 to n^3 steps.

CACM September, 1972

Levitt, K. N.
Kautz, W. H.

graph theory, cellular logic-in-memory arrays,
parallel processing, special purpose computers, 
algorithms for distance and spanning tree problems

5.32 6.22 6.5

CA720901 JB January 30, 1978  9:16 AM

2289	5	2289
2289	5	2289
2289	5	2289
3075	5	2289
3156	5	2289
2289	6	2289
2289	6	2289
2557	6	2289
2664	6	2289
2714	6	2289
2973	6	2289
3075	6	2289


************************



Cellular Arrays for the Solution of Graph Problems

A cellular array is a two-dimensional, checkerboard
type interconnection of identical modules 
(or cells), where each cell contains a few bits of
memory and a small amount of combinational logic, 
and communicates mainly with its immediate neighbors
in the array.  The chief computational advantage 
offered by cellular arrays is the improvement in speed
achieved by virtue of the possibilities for parallel 
processing.  In this paper it is shown that cellular
arrays are inherently well suited for the solution 
of many graph problems.  For example, the adjacency
matrix of a graph is easily mapped onto an array; 
each matrix element is stored in one cell of the array,
and typical row and column operations are readily 
implemented by simple cell logic.  A major challenge
in the effective use of cellular arrays for the 
solution of graph problems is the determination of algorithms
that exploit the possibilities for parallelism, 
especially for problems whose solutions appear to be inherently
serial.  In particular, several parallelized 
algorithms are presented for the solution of certain
spanning tree, distance, and path problems, with 
direct applications to wire routing, PERT chart analysis,
and the analysis of many types of networks. 
 These algorithms exhibit a computation time that in
many cases grows at a rate not exceeding log2 n, 
where n is the number of nodes in the graph.  Straightforward
cellular implementations of the well-known 
serial <B>algorithms for</B> these problems require about n
steps, and noncellular implementations require from 
n^2 to n^3 steps.

CACM September, 1972

Levitt, K. N.
Kautz, W. H.

graph theory, cellular logic-in-memory arrays,
parallel processing, special purpose computers, 
algorithms for distance and spanning tree problems

5.32 6.22 6.5

CA720901 JB January 30, 1978  9:16 AM

2289	5	2289
2289	5	2289
2289	5	2289
3075	5	2289
3156	5	2289
2289	6	2289
2289	6	2289
2557	6	2289
2664	6	2289
2714	6	2289
2973	6	2289
3075	6	2289


************************

************************
Document:  CACM-3018.html
************************


Covering Edges by Cliques with Regard to
Keyword Conflicts and Intersection Graphs

Kellerman has presented a method for determining
keyword conflicts and described a heuristic 
algorithm which solves a certain combinatorial optimization
problem in connection with this method.  
This optimization problem is here shown to be equivalent
to the problem of covering the edges of a graph 
by complete subgraphs with the objective of minimizing
the number of complete subgraphs.  A relationship 
between this edge-clique-cover problem and the <B>graph coloring</B>
problem is established which allows algorithms 
for either one of these problems to be constructed
from algorithm for the other.  As consequences of 
this relationship, the keyword conflict problem and the
edge-clique-cover problem are shown to be NP-complete, 
and if P=/NP then they do not admit polynomial-time approximation
algorithms which always produce solutions 
within a factor less than 2 from the optimum.

CACM February, 1978

Kou, L.
Stockmeyer, L.
Wong, C.
Watson, T.

keyword conflicts, intersection graphs, node clique
cover, edge clique cover, computational complexity, 
NP-complete problems, polynomial-time heuristics

4.12 5.25 5.32

CA780205 JB March 28, 1978  4:18 PM

3018	5	3018
3018	5	3018
3018	5	3018


************************



Covering Edges by Cliques with Regard to
Keyword Conflicts and Intersection Graphs

Kellerman has presented a method for determining
keyword conflicts and described a heuristic 
algorithm which solves a certain combinatorial optimization
problem in connection with <B>this method.</B>  
This optimization problem is here shown to be equivalent
to the problem of covering the edges of a graph 
by complete subgraphs with the objective of minimizing
the number of complete subgraphs.  A relationship 
between this edge-clique-cover problem and the graph coloring
problem is established which allows algorithms 
for either one of these problems to be constructed
from algorithm for the other.  As consequences of 
this relationship, the keyword conflict problem and the
edge-clique-cover problem are shown to be NP-complete, 
and if P=/NP then they do not admit polynomial-time approximation
algorithms which always produce solutions 
within a factor less than 2 from the optimum.

CACM February, 1978

Kou, L.
Stockmeyer, L.
Wong, C.
Watson, T.

keyword conflicts, intersection graphs, node clique
cover, edge clique cover, computational complexity, 
NP-complete problems, polynomial-time heuristics

4.12 5.25 5.32

CA780205 JB March 28, 1978  4:18 PM

3018	5	3018
3018	5	3018
3018	5	3018


************************



Covering Edges by Cliques with Regard to
Keyword Conflicts and Intersection Graphs

Kellerman has presented a method for determining
keyword conflicts and described a heuristic 
algorithm which solves a certain combinatorial optimization
problem in connection with this method.  
This optimization problem is here shown to be equivalent
to the problem of covering the edges of a graph 
by complete subgraphs with the objective of minimizing
the number of complete subgraphs.  A relationship 
between this edge-clique-cover problem and the graph coloring
problem is established which allows algorithms 
for either one of these problems to be constructed
from algorithm <B>for the</B> other.  As consequences of 
this relationship, the keyword conflict problem and the
edge-clique-cover problem are shown to be NP-complete, 
and if P=/NP then they do not admit polynomial-time approximation
algorithms which always produce solutions 
within a factor less than 2 from the optimum.

CACM February, 1978

Kou, L.
Stockmeyer, L.
Wong, C.
Watson, T.

keyword conflicts, intersection graphs, node clique
cover, edge clique cover, computational complexity, 
NP-complete problems, polynomial-time heuristics

4.12 5.25 5.32

CA780205 JB March 28, 1978  4:18 PM

3018	5	3018
3018	5	3018
3018	5	3018


************************



Covering Edges by Cliques with Regard to
Keyword Conflicts and Intersection Graphs

Kellerman has presented a method for determining
keyword conflicts and described a heuristic 
algorithm which solves a certain combinatorial optimization
problem in connection with this method.  
This optimization problem is here shown to be equivalent
to the problem of covering the edges of a graph 
by complete subgraphs with the objective of minimizing
the number of complete subgraphs.  A relationship 
between this edge-clique-cover problem and the graph coloring
problem is established which allows algorithms 
for either one <B>of the</B>se problems to be constructed
from algorithm for the other.  As consequences of 
this relationship, the keyword conflict problem and the
edge-clique-cover problem are shown to be NP-complete, 
and if P=/NP then they do not admit polynomial-time approximation
algorithms which always produce solutions 
within a factor less than 2 from the optimum.

CACM February, 1978

Kou, L.
Stockmeyer, L.
Wong, C.
Watson, T.

keyword conflicts, intersection graphs, node clique
cover, edge clique cover, computational complexity, 
NP-complete problems, polynomial-time heuristics

4.12 5.25 5.32

CA780205 JB March 28, 1978  4:18 PM

3018	5	3018
3018	5	3018
3018	5	3018


************************

************************
Document:  CACM-1698.html
************************


A Statistical Model for Console Behavior in Multiuser Computers

The ability of a computer system to communicate
with the outside world efficiently is as important 
as its ability to perform computations efficiently. 
It is quite difficult to characterize a particular 
user, but rather easy to characterize the entire user community.
 Based <B>on the</B> properties of this community 
we have postulated a hypothetical "virtual console."
 No claim is made that a virtual console behaves 
like any actual console, but the entire collection of
virtual consoles models the collection of actual 
consoles.  Using the model we answer questions like: 
How many processes are suspended waiting for console 
input?  What is the maximum rate at which a process can
execute?  What bounds can be set on overall buffer 
requirements?  Answers to these and similar questions
are needed in certain aspects of operating system 
design.

CACM September, 1968

Denning, P. J.

statistical models for input-output, operating
system design, input-output design

4.30 4.41 5.5

CA680903 JB February 22, 1978  9:21 AM

1458	4	1698
1523	4	1698
1603	4	1698
1698	4	1698
1747	4	1698
1748	4	1698
1854	4	1698
1877	4	1698
1960	4	1698
2377	4	1698
2378	4	1698
2497	4	1698
2558	4	1698
2625	4	1698
2632	4	1698
2840	4	1698
2941	4	1698
3105	4	1698
3144	4	1698
1471	5	1698
1698	5	1698
1698	5	1698
1698	5	1698


************************

************************
Document:  CACM-2283.html
************************


Thinning Algorithms on Rectangular, Hexagonal, and Triangular Arrays

In this report three thinning algorithms are
developed: one each for use with rectangular, 
hexagonal, and triangular arrays.  The approach to the
development of each algorithm is the same.  Pictorial 
results produced by each <B>of the</B> algorithms are presented
and the relative performances of the algorithms 
are compared.  It is found that the algorithm operating
with the triangular array is the most sensitive 
to image irregularities and noise, yet it will yield
a thinned image with an overall reduced number of 
points.  It is concluded that the algorithm operating in
conjunction with the hexagonal array has features 
which strike a balance between those of the other two arrays.

CACM September, 1972

Deutsch, E. S.

thinning algorithms, rectangular, hexagonal,
triangular arrays, image processing, skeleton

3.64

CA720907 JB January 27, 1978  4:25 PM

2283	5	2283
2283	5	2283
2283	5	2283


************************

************************
Document:  CACM-2646.html
************************


A Model for Masking Rotational Latency by Dynamic Disk Allocation

This paper presents the background and algorithms
for masking the rotational latency of a disk 
or drum.  It discusses the anticipatory input and output
of blocks of data to buffer and primary memories 
for a mono-programmed computer system.  A basic permutation
algorithm and several variations are given. 
  Because <B>of the</B> anticipatory nature of the I/O scheduling,
these algorithms are restricted to classes 
of programs with predictable behavior.  While the methods
are not restricted to numerical computations, 
matrix and partial differential equation methods are
typical examples of their use.  It is shown that 
latency may be masked using a small amount of buffer
memory.  The methods discussed are independent of 
the overall size of the data base being considered.

CACM May, 1974

Gold, D. E.
Kuck, D. J.

buffer memory, memory hierarchy, permutation algorithm,
rotational latency, staging, storage allocation

4.41 6.20

CA740507 JB January 17, 1978  3:59 PM

2646	5	2646
2646	5	2646
2646	5	2646


************************

************************
Document:  CACM-3132.html
************************


Experiments with Some Algorithms that Find
Central Solutions for Pattern Classification

In two-class pattern recognition, it is a standard
technique to have an algorithm finding hyperplanes
which separates the two classes in a linearly separable training
set.  The traditional methods find a hyperplane which separates all
points in the other, but such a hyperplane is not necessarily centered
in the empty space between the two classes.  Since a central
hyperplane does not favor one class or the other, it should have
a lower error rate in classifying new points and is therefore better
than a noncentral hyperplane.  Six <B>algorithms for</B> finding central
hyperplanes are tested on three data sets.  Although frequently
used practice, the modified relaxation algorithm is very poor. 
Three algorithms which are defined in the paper are found to be
quite good.

CACM March, 1979

Slagle, J.

Pattern recognition, pattern classification, linear discriminants, central
hyperplanes, centering, centrality criteria, dead zone, hyperplane,
linearly separable, relaxation algorithm, accelerated relaxation

3.62 3.63

CA790303 DH April 12, 1979  3:20 PM

3132	4	3132
2215	5	3132
3132	5	3132
3132	5	3132
3132	5	3132


************************

************************
Document:  CACM-3156.html
************************


Computing Connected Components on Parallel Computers

We present a parallel algorithm which uses n2 processors <B>to find</B> the connected
components of an undirected graph with n vertices in time O(log2n).  An
O(log2n) time bound also can be achieved using only n$n/$log2n)) processors.
The algorithm can be used to find the transitive closure
of a symmetric Boolean matrix.  We assume that the processors have
access to a common memory.  Simultaneous access to the same location
is permitted for fetch instructions but not for store instructions.

CACM August, 1979

Hirschberg, D.
Chandra, A.
Sarwate, D.

Graph theory, parallel processing, algorithms,
transitive closure, connected component

5.25 5.32 6.22

CA790802 DB January 4, 1980  12:18 PM

3075	4	3156
3156	4	3156
3156	4	3156
3156	4	3156
2289	5	3156
2973	5	3156
3075	5	3156
3156	5	3156
3156	5	3156
3156	5	3156


************************

************************
Document:  CACM-1415.html
************************


Automatic Derivation of Microsentences

The decomposition of long complex English sentences
into shorter kernel-like constituent sentences 
(microsentences)has often been suggested as an avenue
toward conducting automatic retrieval of natural 
language messages.  To explore the prospects of such
a step, the authors attempted in 1963 to prepare 
a general program for deriving microsentences from longer
sentences that had been syntactically analyzed 
by the Harvard Multipath Analysis Program.  The basic
idea was to extract the subject, verb and object 
(if any) of each clause and to reassemble these materials
into a grammatical microsentence.  A program 
is described in this paper, which was designed to operate
on the tree structure output <B>of the</B> analyzer, 
and the microsentences that were produced are exhibited.
 The authors conclude that while microsentences 
of the quality achieved do not open up immediate prospects
for improving the performance of automatic 
message retrieval systems, they may have practical
value in man-machine systems using human monitors 
to select the preferred syntactic interpretation of a sentence.

CACM June, 1966

Carmody, B. T
Jones Jr., P. E.

CA660606 JB March 3, 1978  8:47 AM

1415	5	1415
1415	5	1415
1415	5	1415


************************



Automatic Derivation of Microsentences

The decomposition of long complex English sentences
into shorter kernel-like constituent sentences 
(microsentences)has often been suggested as an avenue
toward conducting automatic retrieval of natural 
language messages.  To explore the prospects of such
a step, the authors attempted in 1963 to prepare 
a general program for deriving microsentences from longer
sentences that had been syntactically analyzed 
by the Harvard Multipath Analysis Program.  The basic
idea was to extract the subject, verb and object 
(if any) of each clause and to reassemble these materials
into a grammatical microsentence.  A program 
is described in this paper, which was designed to operate
<B>on the</B> tree structure output of the analyzer, 
and the microsentences that were produced are exhibited.
 The authors conclude that while microsentences 
of the quality achieved do not open up immediate prospects
for improving the performance of automatic 
message retrieval systems, they may have practical
value in man-machine systems using human monitors 
to select the preferred syntactic interpretation of a sentence.

CACM June, 1966

Carmody, B. T
Jones Jr., P. E.

CA660606 JB March 3, 1978  8:47 AM

1415	5	1415
1415	5	1415
1415	5	1415


************************

************************
Document:  CACM-3125.html
************************


Global Optimization by Suppression of Partial Redundancies

The elimination of redundant computations and the moving of invariant
computations out of loops are often done separately, with invariants 
moved outward loop by loop.  We propose to do both at once and
to move each expression directly to the entrance <B>of the</B> outermost
loop in which it is invariant.  This is done by solving a more
general problem, i.e. the elimination of computations performed
twice on a given execution path.  Such computations are termed partially
redundant.  Moreover, the algorithm does not require any graphical
information or restrictions on the shape of the program graph.
Testing this algorithm has shown that its execution cost is nearly
linear with the size of the program, and that it leads
to a smaller optimizer that requires less execution time.

CACM February, 1979

Morel, E.
Renvoise, C.

Optimizer, optimization, compiler, compilation,
redundancy elimination, invariant
 computation elimination, partial redundancy,
data flow analysis, Boolean systems

4.12 5.21 5.24

CA790204 DH April 10, 1979  4:19 PM

3125	5	3125
3125	5	3125
3125	5	3125


************************



Global Optimization by Suppression of Partial Redundancies

The elimination of redundant computations and the moving of invariant
computations out of loops are often done separately, with invariants 
moved outward loop by loop.  We propose to do both at once and
to move each expression directly to the entrance of the outermost
loop in which it is invariant.  This is done by solving a more
general problem, i.e. the elimination of computations performed
twice on a given execution path.  Such computations are termed partially
redundant.  Moreover, the algorithm does not require any graphical
information or restrictions <B>on the</B> shape of the program graph.
Testing this algorithm has shown that its execution cost is nearly
linear with the size of the program, and that it leads
to a smaller optimizer that requires less execution time.

CACM February, 1979

Morel, E.
Renvoise, C.

Optimizer, optimization, compiler, compilation,
redundancy elimination, invariant
 computation elimination, partial redundancy,
data flow analysis, Boolean systems

4.12 5.21 5.24

CA790204 DH April 10, 1979  4:19 PM

3125	5	3125
3125	5	3125
3125	5	3125


************************

************************
Document:  CACM-1934.html
************************


On Arithmetic Expressions and Trees

A description is given of how a tree representing the
evaluation of an arithmetic expression 
can be drawn in such a way that the number of accumulators
needed for the computation can be represented 
in a straightforward manner.  This representation reduces
the choice <B>of the</B> best order of computation 
to a specific problem under the theory of graphs.
 An algorithm to solve this problem is presented.

CACM February, 1969

Redziejowski, R. R.

arithmetic expression, compiler design, graph theory,
programming, storage minimization, topological 
ordering,tree

4.12 5.32

CA690204 JB February 20, 1978  11:11 AM

1807	4	1934
1934	4	1934
2175	4	1934
1551	5	1934
1934	5	1934
1934	5	1934
1934	5	1934


************************



On Arithmetic Expressions and Trees

A description is given of how a tree representing the
evaluation of an arithmetic expression 
can be drawn in such a way that the number of accumulators
needed <B>for the</B> computation can be represented 
in a straightforward manner.  This representation reduces
the choice of the best order of computation 
to a specific problem under the theory of graphs.
 An algorithm to solve this problem is presented.

CACM February, 1969

Redziejowski, R. R.

arithmetic expression, compiler design, graph theory,
programming, storage minimization, topological 
ordering,tree

4.12 5.32

CA690204 JB February 20, 1978  11:11 AM

1807	4	1934
1934	4	1934
2175	4	1934
1551	5	1934
1934	5	1934
1934	5	1934
1934	5	1934


************************

************************
Document:  CACM-1924.html
************************


Organizing Matrices and Matrix Operations for Paged Memory Systems

Matrix representations and operations are examined
<B>for the</B> purpose of minimizing the page faulting 
occurring in a paged memory system.  It is shown that
carefully designed matrix algorithms can lead to 
enormous savings in the number of page faults occurring
when only a small part of the total matrix can 
be in main memory at one time.  Examination of addition,
multiplication, and inversion algorithms shows 
that a partitioned matrix representation (i.e. one submatrix
or partition per page) in most cases induced 
fewer page faults than a row-by-row representation.
 The number of page-pulls required by these matrix 
manipulation algorithms is also studied as a function
of the number of pages of main memory available 
to the algorithm.

CACM March, 1969

McKellar, A. C.
Coffman Jr., E. G.

matrix algorithms, array processing, paging algorithms,
paged memory systems, virtual memory systems, 
array storage allocation, storage allocation

4.12 4.39 5.14

CA690303 JB February 20, 1978  9:35 AM

1892	4	1924
1924	4	1924
2095	4	1924
2218	4	1924
2297	4	1924
2374	4	1924
2526	4	1924
2667	4	1924
2668	4	1924
2862	4	1924
2863	4	1924
1728	5	1924
1924	5	1924
1924	5	1924
1924	5	1924
2365	5	1924
2582	5	1924
3152	5	1924
987	6	1924
1751	6	1924
1754	6	1924
1924	6	1924
1924	6	1924
1924	6	1924
2017	6	1924
2130	6	1924
2362	6	1924
2365	6	1924


************************



Organizing Matrices and Matrix Operations for Paged Memory Systems

Matrix representations and operations are examined
for the purpose of minimizing the page faulting 
occurring in a paged memory system.  It is shown that
carefully designed matrix algorithms can lead to 
enormous savings in the number of page faults occurring
when only a small part <B>of the</B> total matrix can 
be in main memory at one time.  Examination of addition,
multiplication, and inversion algorithms shows 
that a partitioned matrix representation (i.e. one submatrix
or partition per page) in most cases induced 
fewer page faults than a row-by-row representation.
 The number of page-pulls required by these matrix 
manipulation algorithms is also studied as a function
of the number of pages of main memory available 
to the algorithm.

CACM March, 1969

McKellar, A. C.
Coffman Jr., E. G.

matrix algorithms, array processing, paging algorithms,
paged memory systems, virtual memory systems, 
array storage allocation, storage allocation

4.12 4.39 5.14

CA690303 JB February 20, 1978  9:35 AM

1892	4	1924
1924	4	1924
2095	4	1924
2218	4	1924
2297	4	1924
2374	4	1924
2526	4	1924
2667	4	1924
2668	4	1924
2862	4	1924
2863	4	1924
1728	5	1924
1924	5	1924
1924	5	1924
1924	5	1924
2365	5	1924
2582	5	1924
3152	5	1924
987	6	1924
1751	6	1924
1754	6	1924
1924	6	1924
1924	6	1924
1924	6	1924
2017	6	1924
2130	6	1924
2362	6	1924
2365	6	1924


************************

************************
Document:  CACM-1504.html
************************


Algorithms for Finding a Fundamental Set
of Cycles for an Undirected Linear Graph

Given the adjacency matrix <B>of the</B> graph, the algorithm
presented in this paper finds a spanning 
tree and then constructs the set of fundamental cycles.
 Our algorithm is slower than an algorithm presented 
by Welch by a ratio of N/3 (N is the number of nodes)
but requires less storage.  For graphs with a large 
number of nodes and edges, when storage is limited our
algorithm is superior to Welch's; however, when 
the graphs are small, or machine storage is very large,
Welch's algorithm is superior.  Timing estimates 
and storage requirements for both methods are presented.

CACM December, 1967

Gotlieb, C. C.
Corneil, D. G.

CA671204 JB February 26, 19782:35 PM

1504	4	1504
3040	4	1504
1145	5	1504
1504	5	1504
1504	5	1504
1504	5	1504
1847	5	1504
1961	5	1504
2052	5	1504
1008	6	1504
1013	6	1504
1369	6	1504
1504	6	1504
1504	6	1504
1504	6	1504
1540	6	1504
1847	6	1504


************************

************************
Document:  CACM-2883.html
************************


An Application of Heuristic Search Methods to Edge and Contour Detection

This paper presents a method for detecting edges
and contours in noisy pictures.  The properties 
of an edge are embedded in a figure of merit and the edge
detection problem becomes the problem of minimizing 
the given figure of merit.  This problem can be represented
as a shortest path problem on a graph and 
can be solved using well-known graph search algorithms.
 The relations between this representation of 
the minimization problem and a dynamic programming approach
are discussed, showing that the graph search 
method can lead to substantial improvements in computing
time.  Moreover, if heuristic search methods 
are used, the computing time will depend on the amount
of noise in the picture.  Some experimental results 
are given; these show how various information about the
shape <B>of the</B> contour of an object can be embedded
in the figure of merit, thus allowing the extraction
of contours from noisy picture and the separation 
of touching objects.

CACM February, 1976

Martelli, A.

picture processing, pattern recognition, edge
detection, contour detection, contour following, 
optimization problems, dynamic programming, shortest
path, heuristic search methods, problem solving 
methods

3.63 3.64 3.66 5.42

CA760204 JB January 5, 1978  9:30 AM

2883	4	2883
2195	5	2883
2883	5	2883
2883	5	2883
2883	5	2883


************************



An Application of Heuristic Search Methods to Edge and Contour Detection

This paper presents a method for detecting edges
and contours in noisy pictures.  The properties 
of an edge are embedded in a figure of merit and the edge
detection problem becomes the problem of minimizing 
the given figure of merit.  This problem can be represented
as a shortest path problem on a graph and 
can be solved using well-known graph search algorithms.
 The relations between this representation of 
the minimization problem and a dynamic programming approach
are discussed, showing that the graph search 
method can lead to substantial improvements in computing
time.  Moreover, if heuristic search methods 
are used, the computing time will depend <B>on the</B> amount
of noise in the picture.  Some experimental results 
are given; these show how various information about the
shape of the contour of an object can be embedded
in the figure of merit, thus allowing the extraction
of contours from noisy picture and the separation 
of touching objects.

CACM February, 1976

Martelli, A.

picture processing, pattern recognition, edge
detection, contour detection, contour following, 
optimization problems, dynamic programming, shortest
path, heuristic search methods, problem solving 
methods

3.63 3.64 3.66 5.42

CA760204 JB January 5, 1978  9:30 AM

2883	4	2883
2195	5	2883
2883	5	2883
2883	5	2883
2883	5	2883


************************

************************
Document:  CACM-2015.html
************************


A Technique for Generating Almost Optimal
Floyd-Evans Productions for Precedence Grammars

A technique is developed for generating almost optimal Floyd-Evans productions 
given a precedence grammar. A graph formulation is used for the problem of 
merging productions.  The productions generated correspond to the minimum cost 
inverse-arborescence of that graph.  The validity <B>of the</B> technique is
demonstrated for weak precedence grammars defined here, but the productions
mechanically generated for any precedence grammar can often be modified in 
such a way that correct, almost optimal parsers are obtained.

CACM August, 1970

Ichbiah, J. D.
Morse, S. P.

translator writing systems, syntactic analysis, Floyd-Evans
productions, precedence grammars, translator optimization,
merger algorithm, minimum cost inverse-arborescence, graph theory

4.12 5.23 5.32

CA700806 JB February 10, 19783:38 PM

1379	4	2015
1665	4	2015
1693	4	2015
1768	4	2015
1781	4	2015
1787	4	2015
1824	4	2015
1825	4	2015
1836	4	2015
1836	4	2015
1861	4	2015
1945	4	2015
2015	4	2015
2015	4	2015
2060	4	2015
2061	4	2015
2091	4	2015
2110	4	2015
2127	4	2015
2179	4	2015
2187	4	2015
2317	4	2015
2545	4	2015
2546	4	2015
2698	4	2015
2698	4	2015
2708	4	2015
2733	4	2015
3045	4	2015
1477	5	2015
1781	5	2015
2015	5	2015
2015	5	2015
2015	5	2015
2179	5	2015
2423	5	2015
1337	6	2015
1477	6	2015
1491	6	2015
1825	6	2015
2015	6	2015
2015	6	2015
2110	6	2015
3184	6	2015


************************



A Technique for Generating Almost Optimal
Floyd-Evans Productions for Precedence Grammars

A technique is developed for generating almost optimal Floyd-Evans productions 
given a precedence grammar. A graph formulation is used <B>for the</B> problem of 
merging productions.  The productions generated correspond to the minimum cost 
inverse-arborescence of that graph.  The validity of the technique is
demonstrated for weak precedence grammars defined here, but the productions
mechanically generated for any precedence grammar can often be modified in 
such a way that correct, almost optimal parsers are obtained.

CACM August, 1970

Ichbiah, J. D.
Morse, S. P.

translator writing systems, syntactic analysis, Floyd-Evans
productions, precedence grammars, translator optimization,
merger algorithm, minimum cost inverse-arborescence, graph theory

4.12 5.23 5.32

CA700806 JB February 10, 19783:38 PM

1379	4	2015
1665	4	2015
1693	4	2015
1768	4	2015
1781	4	2015
1787	4	2015
1824	4	2015
1825	4	2015
1836	4	2015
1836	4	2015
1861	4	2015
1945	4	2015
2015	4	2015
2015	4	2015
2060	4	2015
2061	4	2015
2091	4	2015
2110	4	2015
2127	4	2015
2179	4	2015
2187	4	2015
2317	4	2015
2545	4	2015
2546	4	2015
2698	4	2015
2698	4	2015
2708	4	2015
2733	4	2015
3045	4	2015
1477	5	2015
1781	5	2015
2015	5	2015
2015	5	2015
2015	5	2015
2179	5	2015
2423	5	2015
1337	6	2015
1477	6	2015
1491	6	2015
1825	6	2015
2015	6	2015
2015	6	2015
2110	6	2015
3184	6	2015


************************

************************
Document:  CACM-2368.html
************************


An Implemented Graph Algorithm for Winning Shannon Switching games

In this tutorial paper a computer program
which wins Shannon Switching Games is described.
 Since these games are played on graphs, the program
is a good example of the implementation of graph 
algorithms.  The two players in a Shannon Switching Game,
CONNECT and CUT, have nonsimilar goals.  Either 
CONNECT, CUT, or the player moving first is guaranteed
the existence of a winning strategy.  The simple 
strategy explained in this paper is valid in all three
cases.  In fact, the major routines never need 
to know whether the computer is CONNECT or CUT.

CACM April, 1972

Chase, S. M.

<B>graph algorithms</B>, graph processing, Shannon Switching
Games, game playing, graph theory, positional 
games, demonstration programs, game theory, spinning trees

3.69 5.32

CA720405 JB January 31, 1978  1:34 PM

2368	5	2368
2368	5	2368
2368	5	2368


************************



An Implemented Graph Algorithm for Winning Shannon Switching games

In this tutorial paper a computer program
which wins Shannon Switching Games is described.
 Since these games are played on graphs, the program
is a good example <B>of the</B> implementation of graph 
algorithms.  The two players in a Shannon Switching Game,
CONNECT and CUT, have nonsimilar goals.  Either 
CONNECT, CUT, or the player moving first is guaranteed
the existence of a winning strategy.  The simple 
strategy explained in this paper is valid in all three
cases.  In fact, the major routines never need 
to know whether the computer is CONNECT or CUT.

CACM April, 1972

Chase, S. M.

graph algorithms, graph processing, Shannon Switching
Games, game playing, graph theory, positional 
games, demonstration programs, game theory, spinning trees

3.69 5.32

CA720405 JB January 31, 1978  1:34 PM

2368	5	2368
2368	5	2368
2368	5	2368


************************

************************
Document:  CACM-2925.html
************************


Optimal Surface Reconstruction from Planar Contours

In many scientific and technical endeavors,
a three-dimensional solid must be reconstructed 
from serial sections, either to aid in the comprehension
<B>of the</B> object's structure or to facilitate its 
automatic manipulation and analysis.  This paper presents
a general solution to the problem of constructing 
a surface over a set of cross-sectional contours. 
This surface, to be composed of triangular tiles, 
is constructed by separately determining an optimal
surface between each pair of consecutive contours.
 Determining such a surface is reduced to the problem
of finding certain minimum cost cycles in a directed 
toroidal graph.  A new fast algorithm for finding such
cycles is utilized.  Also developed is a closed-form 
expression, in term of the number of contour poin ts, for
an upper bound on the number of operations required 
to execute the algorithm.  An illustrated example which
involves the construction of a minimum area surface 
describing a human head is included.

CACM October, 1977

Fuchs, H.
Kedem,Z. M.
Uselton, S. P.

surface reconstruction, contour data, serial sections,
three-dimensional computer graphics, minimum 
cost paths, continuous tone displays

5.25 5.32 8.2

CA771001 JB December 27, 1977  12:40 PM

2925	5	2925
2925	5	2925
2925	5	2925


************************



Optimal Surface Reconstruction from Planar Contours

In many scientific and technical endeavors,
a three-dimensional solid must be reconstructed 
from serial sections, either to aid in the comprehension
of the object's structure or to facilitate its 
automatic manipulation and analysis.  This paper presents
a general solution to the problem of constructing 
a surface over a set of cross-sectional contours. 
This surface, to be composed of triangular tiles, 
is constructed by separately determining an optimal
surface between each pair of consecutive contours.
 Determining such a surface is reduced to the problem
of finding certain minimum cost cycles in a directed 
toroidal graph.  A new fast algorithm for finding such
cycles is utilized.  Also developed is a closed-form 
expression, in term of the number of contour poin ts, for
an upper bound <B>on the</B> number of operations required 
to execute the algorithm.  An illustrated example which
involves the construction of a minimum area surface 
describing a human head is included.

CACM October, 1977

Fuchs, H.
Kedem,Z. M.
Uselton, S. P.

surface reconstruction, contour data, serial sections,
three-dimensional computer graphics, minimum 
cost paths, continuous tone displays

5.25 5.32 8.2

CA771001 JB December 27, 1977  12:40 PM

2925	5	2925
2925	5	2925
2925	5	2925


************************

************************
Document:  CACM-1839.html
************************


Singular Value Decomposition of a Complex
Matrix (Algorithm 358 [F1, 4,5])

CACM October, 1969

Businger, P. A.
Goulub, G. H.

<B>singular value</B>s, matrix decomposition,
least squares solution, pseudoinverse

5.14

CA691007 JB February 15, 1978  3:22 PM

1839	5	1839
1839	5	1839
1839	5	1839


************************

************************
Document:  CACM-3124.html
************************


Recursive Data Structures in APL

A mathematical study of three approaches for defining nested
arrays in APL is presented.  Theorems exhibiting the relationships
between the definitional systems are given and illustrated through graph
representations.  One <B>of the</B> approaches is used to define an
APL array to be a recursive data structure equivalent to a tree structure
in which all data is stored at the leaves as homogeneous
arrays of numbers and characters.  An extension of APL is proposed that
includes new primitive functions to manipulate the nesting
level of arrays and new operators to assist in the
construction of data-driven algorithms.  

CACM February, 1979

Gull,W.
Jenkins, M.

Nested arrays, APL arrays, recursive data structures,
trees, data-driven algorithms, theory of arrays

4.22 5.29

CA790203 DH April 10, 1979  3:41 PM

2060	4	3124
2294	4	3124
2470	4	3124
3124	4	3124
1469	5	3124
3124	5	3124
3124	5	3124
3124	5	3124


************************

************************
Document:  CACM-2146.html
************************


Optimizing the Polyphase Sort

Various dispersion algorithms <B>for the</B> polyphase
sorting procedure are examinedhe optimum 
algorithm based on minimizing the total number of unit
strings read is displayed.  The logic of this 
algorithm is rather complicated; hence, several other
new dispersion algorithms with more straightforward 
logic are presented.  Of the simple dispersion algorithms
discussed, the  Horizontal is best.  It does 
approximately one-fourth to one and one-half percent
less reading and writing than most algorithms in 
use today.  An additional two and one-fourth to three
percent improvement can be achieved by utilizing 
the Modified Optimum Algorithm.  This algorithm is relatively
straightforward, but it requires a fairly 
close estimate of the total number of unit strings before the dispersion begins.

CACM November, 1971

Shell, D. L.

sorting, polyphase sorting, dispersion algorithms,
optimum dispersion algorithm, repetition operator

5.31

CA711103 JB February 2, 1978  11:39 AM

1117	4	2146
1117	4	2146
2017	4	2146
2017	4	2146
2017	4	2146
2146	4	2146
2146	4	2146
2146	4	2146
2146	4	2146
479	4	2146
677	4	2146
860	4	2146
861	4	2146
862	4	2146
863	4	2146
299	5	2146
2146	5	2146
2146	5	2146
2146	5	2146
862	5	2146
863	5	2146
861	5	2146


************************



Optimizing the Polyphase Sort

Various dispersion algorithms for the polyphase
sorting procedure are examinedhe optimum 
algorithm <B>based on</B> minimizing the total number of unit
strings read is displayed.  The logic of this 
algorithm is rather complicated; hence, several other
new dispersion algorithms with more straightforward 
logic are presented.  Of the simple dispersion algorithms
discussed, the  Horizontal is best.  It does 
approximately one-fourth to one and one-half percent
less reading and writing than most algorithms in 
use today.  An additional two and one-fourth to three
percent improvement can be achieved by utilizing 
the Modified Optimum Algorithm.  This algorithm is relatively
straightforward, but it requires a fairly 
close estimate of the total number of unit strings before the dispersion begins.

CACM November, 1971

Shell, D. L.

sorting, polyphase sorting, dispersion algorithms,
optimum dispersion algorithm, repetition operator

5.31

CA711103 JB February 2, 1978  11:39 AM

1117	4	2146
1117	4	2146
2017	4	2146
2017	4	2146
2017	4	2146
2146	4	2146
2146	4	2146
2146	4	2146
2146	4	2146
479	4	2146
677	4	2146
860	4	2146
861	4	2146
862	4	2146
863	4	2146
299	5	2146
2146	5	2146
2146	5	2146
2146	5	2146
862	5	2146
863	5	2146
861	5	2146


************************



Optimizing the Polyphase Sort

Various dispersion <B>algorithms for</B> the polyphase
sorting procedure are examinedhe optimum 
algorithm based on minimizing the total number of unit
strings read is displayed.  The logic of this 
algorithm is rather complicated; hence, several other
new dispersion algorithms with more straightforward 
logic are presented.  Of the simple dispersion algorithms
discussed, the  Horizontal is best.  It does 
approximately one-fourth to one and one-half percent
less reading and writing than most algorithms in 
use today.  An additional two and one-fourth to three
percent improvement can be achieved by utilizing 
the Modified Optimum Algorithm.  This algorithm is relatively
straightforward, but it requires a fairly 
close estimate of the total number of unit strings before the dispersion begins.

CACM November, 1971

Shell, D. L.

sorting, polyphase sorting, dispersion algorithms,
optimum dispersion algorithm, repetition operator

5.31

CA711103 JB February 2, 1978  11:39 AM

1117	4	2146
1117	4	2146
2017	4	2146
2017	4	2146
2017	4	2146
2146	4	2146
2146	4	2146
2146	4	2146
2146	4	2146
479	4	2146
677	4	2146
860	4	2146
861	4	2146
862	4	2146
863	4	2146
299	5	2146
2146	5	2146
2146	5	2146
2146	5	2146
862	5	2146
863	5	2146
861	5	2146


************************



Optimizing the Polyphase Sort

Various dispersion algorithms for the polyphase
sorting procedure are examinedhe optimum 
algorithm based on minimizing the total number of unit
strings read is displayed.  The logic of this 
algorithm is rather complicated; hence, several other
new dispersion algorithms with more straightforward 
logic are presented.  Of the simple dispersion algorithms
discussed, the  Horizontal is best.  It does 
approximately one-fourth to one and one-half percent
less reading and writing than most algorithms in 
use today.  An additional two and one-fourth to three
percent improvement can be achieved by utilizing 
the Modified Optimum Algorithm.  This algorithm is relatively
straightforward, but it requires a fairly 
close estimate <B>of the</B> total number of unit strings before the dispersion begins.

CACM November, 1971

Shell, D. L.

sorting, polyphase sorting, dispersion algorithms,
optimum dispersion algorithm, repetition operator

5.31

CA711103 JB February 2, 1978  11:39 AM

1117	4	2146
1117	4	2146
2017	4	2146
2017	4	2146
2017	4	2146
2146	4	2146
2146	4	2146
2146	4	2146
2146	4	2146
479	4	2146
677	4	2146
860	4	2146
861	4	2146
862	4	2146
863	4	2146
299	5	2146
2146	5	2146
2146	5	2146
2146	5	2146
862	5	2146
863	5	2146
861	5	2146


************************

************************
Document:  CACM-2877.html
************************


A Program Data Flow Analysis Procedure

The global data relationships in a program
can be exposed and codified by the static analysis 
methods described in this paper.  A procedure is given
which determines all the definitions which can
possibly "reach" each node of the control flow graph
of the program and all the definitions that are 
"live" on each edge of <B>the graph.</B>  The procedure uses
an "interval" ordered edge listing data structure 
and handles reducible and irreducible graphs indistinguishably.

CACM March, 1976

Allen, J. E.
Cocke, J.

program optimization, data flow analysis,
flow graphs, algorithms, compilers

4.12 5.24

CA760303 JB January 5, 1978  8:33 AM

2877	5	2877
2877	5	2877
2877	5	2877
3103	5	2877
1860	6	2877
2877	6	2877


************************



A Program Data Flow Analysis Procedure

The global data relationships in a program
can be exposed and codified by the static analysis 
methods described in this paper.  A procedure is given
which determines all the definitions which can
possibly "reach" each node of the control flow graph
of the program and all the definitions <B>that are</B> 
"live" on each edge of the graph.  The procedure uses
an "interval" ordered edge listing data structure 
and handles reducible and irreducible graphs indistinguishably.

CACM March, 1976

Allen, J. E.
Cocke, J.

program optimization, data flow analysis,
flow graphs, algorithms, compilers

4.12 5.24

CA760303 JB January 5, 1978  8:33 AM

2877	5	2877
2877	5	2877
2877	5	2877
3103	5	2877
1860	6	2877
2877	6	2877


************************



A Program Data Flow Analysis Procedure

The global data relationships in a program
can be exposed and codified by the static analysis 
methods described in this paper.  A procedure is given
which determines all the definitions which can
possibly "reach" each node <B>of the</B> control flow graph
of the program and all the definitions that are 
"live" on each edge of the graph.  The procedure uses
an "interval" ordered edge listing data structure 
and handles reducible and irreducible graphs indistinguishably.

CACM March, 1976

Allen, J. E.
Cocke, J.

program optimization, data flow analysis,
flow graphs, algorithms, compilers

4.12 5.24

CA760303 JB January 5, 1978  8:33 AM

2877	5	2877
2877	5	2877
2877	5	2877
3103	5	2877
1860	6	2877
2877	6	2877


************************

************************
Document:  CACM-3164.html
************************


Progressive Acyclic Digraphs-A Tool for Database Integrity

A progressive acyclic digraph (PAD) algorithm accepts are requests and
maintains a graph in an acyclic state.  When a request creates a cycle,
nodes are, "detached" until the new are can be entered acyclically
This process is important in certain areas of database implementation
in which there are constraints <B>on the</B> permissible sequences
of actions. Two PAD algorithms are presented; one uses a simple
path matrix representation and the other uses a list with an
"artificial gradient."  Experiments suggest that for large N the second
is considerably faster, though both are asymptotically O(NR),
where N is the number of nodes and R is the expected number
of nodes reachable along paths from any given node.

CACM September, 1979

Hansen, W.

List processing, data structures, topological sort,
acyclic digraph, database integrity, network, deadlock

4.34 5.32 4.33

CA790905 DB January 14, 1980  11:56 AM

3164	4	3164
1712	5	3164
3164	5	3164
3164	5	3164
3164	5	3164


************************

************************
Document:  CACM-2094.html
************************


On an Algorithm for Nonlinear Minimax Approximation

Certain nonlinear minimax approximation problems are characterize
d by properties which permit the application of special algorithms,
mainly based <B>on the</B> exchange algorithms of Remes (1934, 1935), for
their solution.  In this paper the application to problems of this
type of a general nonlinear algorithm due to Osborne and Watson
(1969) is considered.  Examples are given to illustrate that this
algorithm can give satisfactory results and, in particular, can
successfully solve problems which lead to difficulties
with the more conventional specialist method.

CACM March, 1970

Watson, G. A.

minimax approximation, nonlinear approximation, linear programming

5.13 5.41

CA700304 JB February 13, 1978  4:52 PM

1932	4	2094
2094	4	2094
1566	5	2094
2094	5	2094
2094	5	2094
2094	5	2094
2352	5	2094
2353	5	2094
2094	6	2094
2094	6	2094


************************



On an Algorithm for Nonlinear Minimax Approximation

Certain nonlinear minimax approximation problems are characterize
d by properties which permit the application of special algorithms,
mainly <B>based on</B> the exchange algorithms of Remes (1934, 1935), for
their solution.  In this paper the application to problems of this
type of a general nonlinear algorithm due to Osborne and Watson
(1969) is considered.  Examples are given to illustrate that this
algorithm can give satisfactory results and, in particular, can
successfully solve problems which lead to difficulties
with the more conventional specialist method.

CACM March, 1970

Watson, G. A.

minimax approximation, nonlinear approximation, linear programming

5.13 5.41

CA700304 JB February 13, 1978  4:52 PM

1932	4	2094
2094	4	2094
1566	5	2094
2094	5	2094
2094	5	2094
2094	5	2094
2352	5	2094
2353	5	2094
2094	6	2094
2094	6	2094


************************

************************
Document:  CACM-1727.html
************************


One Way of Estimating Frequencies of Jumps in a Program

For the segmentation of a program it is useful
to have a reasonable estimation <B>of the</B> values 
of S(ij), where S(ij) is the mean value of the number
of jumps from the i-th instruction on to the j-th 
instruction in the run time.  In the cases where the
S(ij) are estimated directly, the structure of the 
whole program must be generally taken into account;
therefore it is very difficult for the programmer 
and/or the translator to obtain a good estimation of
the S(ij).  It is easier to estimate not S(ij) but 
the quantities P(ij)=S(ij)*C(i)/SUM[S(ij), j=1,N], where
C(i) is an arbitrary positive constant for each 
i.  Although the P(ij) are, for each i, proportional to
S(ij), the estimation of P(ij) is easier, because 
we must estimate only the "probabilities" of events
where instruction i is executed after instruction 
I(i).  This estimation can often be done without considering
the structure of the whole program.  In 
the first part of the paper, using the theory of the
Markov chains, an algorithm for the computation 
of the S(ij) from the P(ij) is found, and some ways
of obtaining estimates of the P(ij) are given.  In 
the second part a variant of this algorithm is derived,
avoiding the necessity of computation involving 
large matrices.

CACM July, 1968

Kral, J.

object program reduction, supervisor calls decreasing,
jump frequencies estimation, control transfers 
estimation, optimal program segmentation, Markov chain
program correspondence, program graph, one-entry 
subgraph, locally estimated jump frequencies, supervisor
overhead decreasing, program segmentation algorithm, 
jump frequencies, program segmentation problem

4.11 4.19 4.39 4.49

CA680702 JB February 22, 1978  3:05 PM

1727	5	1727
1727	5	1727
1727	5	1727


************************



One Way of Estimating Frequencies of Jumps in a Program

For the segmentation of a program it is useful
to have a reasonable estimation of the values 
of S(ij), where S(ij) is the mean value of the number
of jumps from the i-th instruction on to the j-th 
instruction in the run time.  In the cases where the
S(ij) are estimated directly, the structure of the 
whole program must be generally taken into account;
therefore it is very difficult <B>for the</B> programmer 
and/or the translator to obtain a good estimation of
the S(ij).  It is easier to estimate not S(ij) but 
the quantities P(ij)=S(ij)*C(i)/SUM[S(ij), j=1,N], where
C(i) is an arbitrary positive constant for each 
i.  Although the P(ij) are, for each i, proportional to
S(ij), the estimation of P(ij) is easier, because 
we must estimate only the "probabilities" of events
where instruction i is executed after instruction 
I(i).  This estimation can often be done without considering
the structure of the whole program.  In 
the first part of the paper, using the theory of the
Markov chains, an algorithm for the computation 
of the S(ij) from the P(ij) is found, and some ways
of obtaining estimates of the P(ij) are given.  In 
the second part a variant of this algorithm is derived,
avoiding the necessity of computation involving 
large matrices.

CACM July, 1968

Kral, J.

object program reduction, supervisor calls decreasing,
jump frequencies estimation, control transfers 
estimation, optimal program segmentation, Markov chain
program correspondence, program graph, one-entry 
subgraph, locally estimated jump frequencies, supervisor
overhead decreasing, program segmentation algorithm, 
jump frequencies, program segmentation problem

4.11 4.19 4.39 4.49

CA680702 JB February 22, 1978  3:05 PM

1727	5	1727
1727	5	1727
1727	5	1727


************************

************************
Document:  CACM-3085.html
************************


An O(n) Algorithm for Determining a Near-Optimal
Computation Order of Matrix Chain Products

This paper discusses the computation of matrix
chain products of the form M1 x M2 x ... x Mn 
where Mi's are matrices.  The order in which the matrices
are computed affects the number of operations. 
 A sufficient condition about the association of the
matrices in the optimal order is presented.  An 
O(n) algorithm <B>to find</B> an order of computation which
takes less than 25 percent longer than the optimal 
time Topt is also presented.  In most cases, the algorithm
yields the optimal order or an order which 
takes only a few percent longer than Topt (less than 1 percent on the average).

CACM July, 1978

Chin, F.

Approximate algorithm, heuristic algorithm,
matrix multiplication, matrix chain product

5.14

CA780703 DH February 8, 1979  2:46 PM

3075	4	3085
3085	4	3085
2557	5	3085
3085	5	3085
3085	5	3085
3085	5	3085


************************



An O(n) Algorithm for Determining a Near-Optimal
Computation Order of Matrix Chain Products

This paper discusses the computation of matrix
chain products <B>of the</B> form M1 x M2 x ... x Mn 
where Mi's are matrices.  The order in which the matrices
are computed affects the number of operations. 
 A sufficient condition about the association of the
matrices in the optimal order is presented.  An 
O(n) algorithm to find an order of computation which
takes less than 25 percent longer than the optimal 
time Topt is also presented.  In most cases, the algorithm
yields the optimal order or an order which 
takes only a few percent longer than Topt (less than 1 percent on the average).

CACM July, 1978

Chin, F.

Approximate algorithm, heuristic algorithm,
matrix multiplication, matrix chain product

5.14

CA780703 DH February 8, 1979  2:46 PM

3075	4	3085
3085	4	3085
2557	5	3085
3085	5	3085
3085	5	3085
3085	5	3085


************************



An O(n) Algorithm for Determining a Near-Optimal
Computation Order of Matrix Chain Products

This paper discusses the computation of matrix
chain products of the form M1 x M2 x ... x Mn 
where Mi's are matrices.  The order in which the matrices
are computed affects the number of operations. 
 A sufficient condition about the association of the
matrices in the optimal order is presented.  An 
O(n) algorithm to find an order of computation which
takes less than 25 percent longer than the optimal 
time Topt is also presented.  In most cases, the algorithm
yields the optimal order or an order which 
takes only a few percent longer than Topt (less than 1 percent <B>on the</B> average).

CACM July, 1978

Chin, F.

Approximate algorithm, heuristic algorithm,
matrix multiplication, matrix chain product

5.14

CA780703 DH February 8, 1979  2:46 PM

3075	4	3085
3085	4	3085
2557	5	3085
3085	5	3085
3085	5	3085
3085	5	3085


************************

************************
Document:  CACM-2606.html
************************


A New Integration Algorithm for Ordinary Differential
Equations Based on Continued Fraction Approximations

A new integration algorithm is found, and an
implementation is compared with other programmed 
algorithms.  The new algorithm is a step-by-step procedure
for solving the initial value problem in ordinary 
differential equations.  It is designed to approximate
poles of small integer order in the solutions 
<B>of the</B> differential equations by continued fractions obtained
by manipulating the sums of truncated Taylor 
series expansions.  The new method is compared with
Gragg-Bulirsh-Stoer, and the Taylor series method. 
 The Taylor series method and the new method are shown
to be superior in speed and accuracy, while the 
new method is shown to be most superior when the solution
is required near a singularity.  The new method 
can finally be seen to pass automatically through singularities
where all the other methods which are 
discussed will have failed.

CACM September, 1974

Willers, I. M.

ordinary differential equations, initial value problem,
integration, Taylor series, singularities, 
continued fractions, program comparison

5.17

CA740902 JB January 17, 1978  9:06 AM

2606	5	2606
2606	5	2606
2606	5	2606


************************

************************
Document:  CACM-1721.html
************************


Determination <B>of the</B> Intersection Points of Two
Plane Curves by Means of Differential Equations

A new method is proposed to calculate the intersection
points of two plane curves.  The theory 
of singular points off a system of two differential equations
is used in developing the method. The intersection 
point to be determined is identified with such a singular
point and appropriate modifications are applied 
to the system to ensure that the singular point be stable,
i.e. all integrals which start in the neighborhood 
of the singular point will always approach this point
if the integral parameter tends to infinity.  In 
addition a method is described for systematically searching
for all intersection points in a prescribed 
rectangular area.

CACM July, 1968

Kuiken, H. K.

plane curves, intersection points, intersections
plane curves, integration, differential equations, 
matrix iteration, singular points, nonlinear differential
equations, eigenvalues, complex roots, roots, 
stationary points, Runge Kutta, stable singularity, unstable singularity

2.0 3.10 3.20 3.50 5.10

CA680708 JB February 22, 1978  11:51 AM

1721	5	1721
1721	5	1721
1721	5	1721


************************

************************
Document:  CACM-2200.html
************************


On Complement Division

The division algorithm theorem is expressed
in a form that permits it to serve as the basis 
for devising division operations that produce both quotient
and remainder in complement form.  Algorithms 
for division yielding complement results are derived
for numbers represented <B>in any</B> base greater than 
one.  Both radix and radix-less-one complementation schemes
are considered.  The binary form of the algorithms 
thus includes both two's and one's complement implementation.
 The problem of quotient overflow for complement 
results is dealt with as is that of selecting an appropriate
form of the remainder condition for complement 
division. 

CACM April, 1971

Stein, M. L.
Munro, W. D.

division algorithm, complement arithmetic, complement
division, one's complement arithmetic, two's 
complement arithmetic

3.15 4.0 4.9 5.11 6.32

CA710405 JB February 3, 1978  3:28 PM

1965	4	2200
2200	4	2200
1718	5	2200
2200	5	2200
2200	5	2200
2200	5	2200


************************



On Complement Division

The division algorithm theorem is expressed
in a form that permits it to serve as the basis 
for devising division operations that produce both quotient
and remainder in complement form.  Algorithms 
for division yielding complement results are derived
for numbers represented in any base greater than 
one.  Both radix and radix-less-one complementation schemes
are considered.  The binary form <B>of the</B> algorithms 
thus includes both two's and one's complement implementation.
 The problem of quotient overflow for complement 
results is dealt with as is that of selecting an appropriate
form of the remainder condition for complement 
division. 

CACM April, 1971

Stein, M. L.
Munro, W. D.

division algorithm, complement arithmetic, complement
division, one's complement arithmetic, two's 
complement arithmetic

3.15 4.0 4.9 5.11 6.32

CA710405 JB February 3, 1978  3:28 PM

1965	4	2200
2200	4	2200
1718	5	2200
2200	5	2200
2200	5	2200
2200	5	2200


************************

************************
Document:  CACM-2561.html
************************


A Heuristic Approach to Inductive Inference in Fact Retrieval Systems

Heuristic procedures are presented which have
been developed to perform inferences by generalizing 
from available information.  The procedures make use
of a similarity structure which is imposed <B>on the</B> 
data base using nonnumerical clustering algorithms.  They
are implemented in a model fact retrieval system 
which uses a formal query language and a property-list data
structure.  A program of experiments is described 
wherein the procedures are used with test data bases
which are altered by deleting part of the data and 
by purposely introducing false data.  It is found that
the system can infer the correct response under 
a variety of conditions involving incomplete and inconsistent data.

CACM December, 1974

Skinner, C. W.

inference, inductive inference, clustering, fact retrieval, heuristics

3.61 3.71 3.79

CA741213 JB January 13, 1978  3:40 PM

2178	4	2561
2396	4	2561
2561	4	2561
2127	5	2561
2561	5	2561
2561	5	2561
2561	5	2561


************************



A Heuristic Approach to Inductive Inference in Fact Retrieval Systems

Heuristic procedures are presented which have
been developed to perform inferences by generalizing 
from available information.  The procedures make use
of a similarity structure which is imposed on the 
data base using nonnumerical clustering algorithms.  They
are implemented in a model fact retrieval system 
which uses a formal query language and a property-list data
structure.  A program of experiments is described 
wherein the procedures are used with test data bases
which are altered by deleting part <B>of the</B> data and 
by purposely introducing false data.  It is found that
the system can infer the correct response under 
a variety of conditions involving incomplete and inconsistent data.

CACM December, 1974

Skinner, C. W.

inference, inductive inference, clustering, fact retrieval, heuristics

3.61 3.71 3.79

CA741213 JB January 13, 1978  3:40 PM

2178	4	2561
2396	4	2561
2561	4	2561
2127	5	2561
2561	5	2561
2561	5	2561
2561	5	2561


************************

************************
Document:  CACM-2524.html
************************


Some Approaches to Best-Match File Searching

The problem of searching the set of keys in
a file to find a key which is closest to a given 
query key is discussed.  After "closest," in terms of
a metric on the the key space, is suitably defined, 
three file structures are presented together with their
corresponding search algorithms, which are intended 
to reduce the number of comparisons required to achieve
the desired result. These methods are derived 
using certain inequalities satisfied by metrics and by
graph-theoretic concepts.  Some empirical results 
are presented which compare the efficiency <B>of the</B> methods.

CACM April, 1973

Burkhard, W. A.
Keller, R. M.

matching, file structuring, file searching, heuristics, best match

3.73 3.79 4.9

CA730404 JB January 24, 1978  9:54 AM

1676	4	2524
1682	4	2524
1728	4	2524
1860	4	2524
1973	4	2524
2018	4	2524
2032	4	2524
2033	4	2524
2107	4	2524
2109	4	2524
2203	4	2524
2251	4	2524
2359	4	2524
2524	4	2524
2543	4	2524
2552	4	2524
2559	4	2524
2991	4	2524
3053	4	2524
1785	5	2524
2524	5	2524
2524	5	2524
2524	5	2524
2575	5	2524
2966	5	2524
3134	5	2524
1976	6	2524
2160	6	2524
2524	6	2524
2524	6	2524
2524	6	2524
2990	6	2524


************************



Some Approaches to Best-Match File Searching

The problem of searching the set of keys in
a file <B>to find</B> a key which is closest to a given 
query key is discussed.  After "closest," in terms of
a metric on the the key space, is suitably defined, 
three file structures are presented together with their
corresponding search algorithms, which are intended 
to reduce the number of comparisons required to achieve
the desired result. These methods are derived 
using certain inequalities satisfied by metrics and by
graph-theoretic concepts.  Some empirical results 
are presented which compare the efficiency of the methods.

CACM April, 1973

Burkhard, W. A.
Keller, R. M.

matching, file structuring, file searching, heuristics, best match

3.73 3.79 4.9

CA730404 JB January 24, 1978  9:54 AM

1676	4	2524
1682	4	2524
1728	4	2524
1860	4	2524
1973	4	2524
2018	4	2524
2032	4	2524
2033	4	2524
2107	4	2524
2109	4	2524
2203	4	2524
2251	4	2524
2359	4	2524
2524	4	2524
2543	4	2524
2552	4	2524
2559	4	2524
2991	4	2524
3053	4	2524
1785	5	2524
2524	5	2524
2524	5	2524
2524	5	2524
2575	5	2524
2966	5	2524
3134	5	2524
1976	6	2524
2160	6	2524
2524	6	2524
2524	6	2524
2524	6	2524
2990	6	2524


************************



Some Approaches to Best-Match File Searching

The problem of searching the set of keys in
a file to find a key which is closest to a given 
query key is discussed.  After "closest," in terms of
a metric <B>on the</B> the key space, is suitably defined, 
three file structures are presented together with their
corresponding search algorithms, which are intended 
to reduce the number of comparisons required to achieve
the desired result. These methods are derived 
using certain inequalities satisfied by metrics and by
graph-theoretic concepts.  Some empirical results 
are presented which compare the efficiency of the methods.

CACM April, 1973

Burkhard, W. A.
Keller, R. M.

matching, file structuring, file searching, heuristics, best match

3.73 3.79 4.9

CA730404 JB January 24, 1978  9:54 AM

1676	4	2524
1682	4	2524
1728	4	2524
1860	4	2524
1973	4	2524
2018	4	2524
2032	4	2524
2033	4	2524
2107	4	2524
2109	4	2524
2203	4	2524
2251	4	2524
2359	4	2524
2524	4	2524
2543	4	2524
2552	4	2524
2559	4	2524
2991	4	2524
3053	4	2524
1785	5	2524
2524	5	2524
2524	5	2524
2524	5	2524
2575	5	2524
2966	5	2524
3134	5	2524
1976	6	2524
2160	6	2524
2524	6	2524
2524	6	2524
2524	6	2524
2990	6	2524


************************

************************
Document:  CACM-2059.html
************************


A Language for Treating Graphs

A language <B>for the</B> representation of graph is described, and the formulation of 
graph operations such as node and/or link deletion or insertion, union, 
intersection, comparison, and traversal of graphs is given.  Graphs
are represented by linked lists.  The language is syntactically defined
as an extension to ALGOL 60, and it is translated into ALGOL
by means of a syntax-driven compiler.  Application areas for this language are
operation research, network problems, control theory, traffic problems, etc.

CACM May, 1970

Crespi-Reghizzi, S.
Morpurgo, R.

graphs, oriented, nonoriented, multiple,
colored graph, language extended ALGOL,
operator-precedence, syntax-driven compiler,
operation research, network, traffic

3.2 3.5 4.2 5.3

CA700507 JB February 13, 1978  1:31 PM

249	4	2059
254	4	2059
272	4	2059
1102	4	2059
1109	4	2059
1140	4	2059
1188	4	2059
1306	4	2059
1464	4	2059
1491	4	2059
1767	4	2059
1781	4	2059
1787	4	2059
1949	4	2059
321	4	2059
2059	4	2059
2126	4	2059
435	4	2059
437	4	2059
463	4	2059
483	4	2059
491	4	2059
2732	4	2059
560	4	2059
583	4	2059
3073	4	2059
627	4	2059
631	4	2059
632	4	2059
642	4	2059
644	4	2059
653	4	2059
680	4	2059
761	4	2059
762	4	2059
763	4	2059
123	4	2059
140	4	2059
919	4	2059
989	4	2059
196	5	2059
2059	5	2059
2059	5	2059
2059	5	2059
2178	5	2059
1303	6	2059
1323	6	2059
2059	6	2059
2127	6	2059
3184	6	2059


************************

************************
Document:  CACM-2178.html
************************


A Language Extension for Graph Processing and Its Formal Semantics

A simple programming language "extension,"
Graspe, for processing directed graphs is defined. 
 Graspe consists of a type of directed graph data structure
and a set of primitive operations for manipulating 
these structures.  Graspe may be most easily implemented
by embedding it in a host language.  Emphasis 
is placed both on Graspe itself and on its method of
definition.  Commonly, the definition of a language 
involves definition <B>of the</B> syntactic elements and explanation
of the meaning to be assigned them (the 
semantics).  The definition of Graspe here is solely in
terms of its semantics; that is, the data structures 
and operations are defined precisely but without assignment
of a particular syntactic representation. 
 Only when the language is implemented is assignment
of an explicit syntax necessary.  An example of 
an implementation of Graspe embedded in Lisp is given as
an illustration.  The advantages and disadvantages 
of the definition of a language in terms of its semantics are discussed.

CACM July, 1971

Pratt, T. W.
Friedman, D. P.

graph processing, programming language, formal semantics,
directed graph, Lisp, network, data structure, 
flowchart, syntax, language definition

4.20 4.22 5.23 5.24 5.32

CA710704 JB February 3, 1978  9:24 AM

1086	4	2178
1132	4	2178
1234	4	2178
1263	4	2178
1265	4	2178
1270	4	2178
1323	4	2178
1358	4	2178
1379	4	2178
1380	4	2178
1453	4	2178
1464	4	2178
1469	4	2178
1484	4	2178
1486	4	2178
1491	4	2178
1491	4	2178
1498	4	2178
1613	4	2178
1614	4	2178
1781	4	2178
1781	4	2178
1781	4	2178
1825	4	2178
1860	4	2178
2083	4	2178
2178	4	2178
2178	4	2178
2178	4	2178
2178	4	2178
2178	4	2178
2179	4	2178
2252	4	2178
2325	4	2178
2326	4	2178
2326	4	2178
2341	4	2178
2396	4	2178
2470	4	2178
2546	4	2178
2561	4	2178
2645	4	2178
2652	4	2178
2684	4	2178
2684	4	2178
2684	4	2178
2842	4	2178
2929	4	2178
2934	4	2178
3044	4	2178
3069	4	2178
669	4	2178
679	4	2178
691	4	2178
761	4	2178
949	4	2178
989	4	2178
1303	5	2178
1323	5	2178
2059	5	2178
2127	5	2178
2178	5	2178
2178	5	2178
2178	5	2178
3184	5	2178


************************

************************
Document:  CACM-2142.html
************************


Reconstruction of Pictures from Their Projections

There are situations in the natural sciences
and medicine (e.g. in electron microscopy and 
X-ray photography) in which it is desirable to estimate the
gray levels of a digital picture at the individual 
points from the sums of the gray levels along straight
lines (projections) at a few angles.  Usually, 
in such situations, the picture is far from determined
and the problem is <B>to find</B> the "most representative" 
picture.  Three algorithms are described (all using
Monte Carlo methods) which were designed to solve 
this problem.  The algorithms are applicable in a large
and varied number of fields.  The most important 
uses may be the reconstruction of possibly asymmetric particles
from electron micrographs and three-dimensional 
X-ray analysis.

CACM December, 1971

Gordon,R.
Herman, G. T.

approximation, biomedical image processing, efficient
encoding, image processing, linear programming, 
mathematical programming, Monte Carlo techniques, optimization,
picture compression, picture description, 
picture processing, stereology, X-ray analysis

3.12 3.13 3.15 3.17 3.63 5.41 5.6

CA711201 JB February 2, 1978  10:32 AM

2142	4	2142
2142	4	2142
2529	4	2142
1929	5	2142
2142	5	2142
2142	5	2142
2142	5	2142
2231	5	2142


************************



Reconstruction of Pictures from Their Projections

There are situations in the natural sciences
and medicine (e.g. in electron microscopy and 
X-ray photography) in which it is desirable to estimate the
gray levels of a digital picture at the individual 
points from the sums <B>of the</B> gray levels along straight
lines (projections) at a few angles.  Usually, 
in such situations, the picture is far from determined
and the problem is to find the "most representative" 
picture.  Three algorithms are described (all using
Monte Carlo methods) which were designed to solve 
this problem.  The algorithms are applicable in a large
and varied number of fields.  The most important 
uses may be the reconstruction of possibly asymmetric particles
from electron micrographs and three-dimensional 
X-ray analysis.

CACM December, 1971

Gordon,R.
Herman, G. T.

approximation, biomedical image processing, efficient
encoding, image processing, linear programming, 
mathematical programming, Monte Carlo techniques, optimization,
picture compression, picture description, 
picture processing, stereology, X-ray analysis

3.12 3.13 3.15 3.17 3.63 5.41 5.6

CA711201 JB February 2, 1978  10:32 AM

2142	4	2142
2142	4	2142
2529	4	2142
1929	5	2142
2142	5	2142
2142	5	2142
2142	5	2142
2231	5	2142


************************

************************
Document:  CACM-3139.html
************************


New Methods to Color the Vertices of a Graph

This paper describes efficient new heuristic
methods to color the vertices of a graph which rely
upon the comparison <B>of the</B> degrees and structure of a graph.  A method
is developed which is exact for bipartite graphs and is an
important part of heuristic procedures to find maximal cliques in general
graphs.  Finally an exact method is given which performs better
than the Randall-Brown algorithm and is able to color larger
graphs, and the new heuristic methods, the classical methods, and
the exact method are compared.  

CACM April, 1979

Brelaz, D.

NP-complete, graph structure, balancing, graph
coloring, scheduling, comparison of the methods

5.25 5.32

CA790405 DH June 5, 1979  2:05 PM

3139	5	3139
3139	5	3139
3139	5	3139


************************



New Methods to Color the Vertices of a Graph

This paper describes efficient new heuristic
methods to color the vertices of a graph which rely
upon the comparison of the degrees and structure of a graph.  A method
is developed which is exact for bipartite graphs and is an
important part of heuristic procedures <B>to find</B> maximal cliques in general
graphs.  Finally an exact method is given which performs better
than the Randall-Brown algorithm and is able to color larger
graphs, and the new heuristic methods, the classical methods, and
the exact method are compared.  

CACM April, 1979

Brelaz, D.

NP-complete, graph structure, balancing, graph
coloring, scheduling, comparison of the methods

5.25 5.32

CA790405 DH June 5, 1979  2:05 PM

3139	5	3139
3139	5	3139
3139	5	3139


************************



New Methods to Color the Vertices of a Graph

This paper describes efficient new heuristic
methods to color the vertices of a graph which rely
up<B>on the</B> comparison of the degrees and structure of a graph.  A method
is developed which is exact for bipartite graphs and is an
important part of heuristic procedures to find maximal cliques in general
graphs.  Finally an exact method is given which performs better
than the Randall-Brown algorithm and is able to color larger
graphs, and the new heuristic methods, the classical methods, and
the exact method are compared.  

CACM April, 1979

Brelaz, D.

NP-complete, graph structure, balancing, graph
coloring, scheduling, comparison of the methods

5.25 5.32

CA790405 DH June 5, 1979  2:05 PM

3139	5	3139
3139	5	3139
3139	5	3139


************************

************************
Document:  CACM-3033.html
************************


Optimizing Decision Trees Through Heuristically Guided Search

Optimal decision table conversion has been
tackled in the literature using two approaches, 
dynamic programming and branch-and-bound.  The former
technique is quite effective, but its time and 
space requirements are independent of how "easy" the
given table is.  Furthermore, it cannot be used 
to produce good, quasi optimal solutions.  The branch-and-bound
technique uses a good heuristic to direct 
the search, but is cluttered up by an enormous search
space, since the number of solutions increases 
with the number of test variables according to a double 
exponential.  In this paper we suggest a heuristically 
guided top-down search algorithm which, like dynamic
programming, recognizes identical subproblems but 
which can be used <B>to find</B> both optimal and quasi optimal
solutions.  The heuristic search method introduced 
in this paper combines the positive aspects of the above
two techniques.  Compressed tables with a large 
number of variables can be handled without deriving expanded tables first. 

CACM December, 1978

Martelli, A.
Montanari, U.

Decision table, optimal decision table conversion,
decision tree, heuristic search, AND/OR graphs, 
dynamic programming, branch-and-bound

3.59 3.66 5.42 8.3

CA781206 DH January 18, 1979  3:56 PM

3033	4	3033
3113	4	3033
2856	5	3033
3033	5	3033
3033	5	3033
3033	5	3033


************************



Optimizing Decision Trees Through Heuristically Guided Search

Optimal decision table conversion has been
tackled in the literature using two approaches, 
dynamic programming and branch-and-bound.  The former
technique is quite effective, but its time and 
space requirements are independent of how "easy" the
given table is.  Furthermore, it cannot be used 
to produce good, quasi optimal solutions.  The branch-and-bound
technique uses a good heuristic to direct 
the search, but is cluttered up by an enormous search
space, since the number of solutions increases 
with the number of test variables according to a double 
exponential.  In this paper we suggest a heuristically 
guided top-down search algorithm which, like dynamic
programming, recognizes identical subproblems but 
which can be used to find both optimal and quasi optimal
solutions.  The heuristic search method introduced 
in this paper combines the positive aspects <B>of the</B> above
two techniques.  Compressed tables with a large 
number of variables can be handled without deriving expanded tables first. 

CACM December, 1978

Martelli, A.
Montanari, U.

Decision table, optimal decision table conversion,
decision tree, heuristic search, AND/OR graphs, 
dynamic programming, branch-and-bound

3.59 3.66 5.42 8.3

CA781206 DH January 18, 1979  3:56 PM

3033	4	3033
3113	4	3033
2856	5	3033
3033	5	3033
3033	5	3033
3033	5	3033


************************

************************
Document:  CACM-1529.html
************************


Decomposition Programming An Analysis of Matrix Substructure 

A petroleum blending problem was analyzed in order
to compare the primal and primal-dual decomposition 
algorithms.  In the course <B>of the</B> analysis, a substructure
was discovered which has relevance to the 
relative performance of the two algorithms and to their
absolute performance as compared with a standard 
primal-Simplex solution without decomposition.

CACM October, 1967

Bell, E. J.

CA671004 JB February 27, 1978  2:33 PM

1529	5	1529
1529	5	1529
1529	5	1529


************************

************************
Document:  CACM-2402.html
************************


Pictorial Pattern Recognition and the
Phase Problem of X-ray Crystallography

The availability of interactive, three-dimensional,
computer graphics systems coupled to powerful 
digital computers encourages the development of algorithms
adapted to this environment.  Pictorial pattern 
recognition techniques make possible a number of approaches
to X-ray structure determination based on 
molecular model building, i.e. the use of chemical information
to frame "structural hypotheses" which 
can computationally be tested and refined by reference
to the experimental data.  Application of standard 
pattern recognition algorithms is hindered by the fact
that the cross-correlation between a model and 
the correct structure cannot be computed because of
a fundamental incompleteness in the measured data. 
 However, it is possible to compute an upper bound to such
a cross-correlation.  A simple example demonstrates 
that this information can be the basis of a technique
for structure determination that can make effective 
use of an interactive graphics system. Model building
by cross-correlations has intrinsic advantages 
over usual crystallographic techniques based <B>on the</B>
autocorrelation or Patterson function, especially 
for large structures.  This is significant, for crystallography
of biological macromolecules hasbeen 
and will continue to be a field of intense interest.

CACM January, 1972

Lesk, A. M.

pictorial pattern recognition, phase problem,
X-ray crystallography, interactive graphics

3.13 3.17 3.63

CA720101 JB February 1, 1978  9:53 AM

2402	5	2402
2402	5	2402
2402	5	2402


************************



Pictorial Pattern Recognition and the
Phase Problem of X-ray Crystallography

The availability of interactive, three-dimensional,
computer graphics systems coupled to powerful 
digital computers encourages the development of algorithms
adapted to this environment.  Pictorial pattern 
recognition techniques make possible a number of approaches
to X-ray structure determination <B>based on</B> 
molecular model building, i.e. the use of chemical information
to frame "structural hypotheses" which 
can computationally be tested and refined by reference
to the experimental data.  Application of standard 
pattern recognition algorithms is hindered by the fact
that the cross-correlation between a model and 
the correct structure cannot be computed because of
a fundamental incompleteness in the measured data. 
 However, it is possible to compute an upper bound to such
a cross-correlation.  A simple example demonstrates 
that this information can be the basis of a technique
for structure determination that can make effective 
use of an interactive graphics system. Model building
by cross-correlations has intrinsic advantages 
over usual crystallographic techniques based on the
autocorrelation or Patterson function, especially 
for large structures.  This is significant, for crystallography
of biological macromolecules hasbeen 
and will continue to be a field of intense interest.

CACM January, 1972

Lesk, A. M.

pictorial pattern recognition, phase problem,
X-ray crystallography, interactive graphics

3.13 3.17 3.63

CA720101 JB February 1, 1978  9:53 AM

2402	5	2402
2402	5	2402
2402	5	2402


************************

************************
Document:  CACM-3172.html
************************


An Algorithm for Planning Collision-Free
Paths Among Polyhedral Obstacles

This paper describes a collision avoidance algorithm
for planning a safe path for a polyhedral object moving among
known polyhedral objects.  The algorithm transforms the obstacles
so that they represent the locus of forbidden positions for an arbitrary
reference point <B>on the</B> moving object.  A trajectory of this
reference point which avoids all forbidden regions is free of collisions.
Trajectories are found by searching a network which indicates, for each vertex 
in the transformed obstacles, which other vertices can be reached safely.

CACM October, 1979

Lozano-Perez, T.
Wesley, M.

Path finding, collision-free paths, polyhedral objects,
polyhedral obstacles, graph searching, growing objects

3.15 3.64 3.66 8.1

CA791005 DB January 17, 1980  10:13 AM

3172	4	3172
3116	5	3172
3172	5	3172
3172	5	3172
3172	5	3172


************************

************************
Document:  CACM-2189.html
************************


Generation of Rosary Permutations Expressed in Hamiltonian Circuits

Systematic generation of a specific class
of permutations fundamental to scheduling problems 
is described.  In a nonoriented complete graph with
n vertices, Hamitonian circuits equivalent to .5(n 
- 1)! specific permutations of n elements, termed rosary
permutations, can be defined.  Each <B>of the</B>m 
corresponds to two circular permutations which mirror-image
each other, and is generated successively 
by a number system covering 3*4*...*(n-1) sets of edges.
 Every set of edges {E[k]}, 1 <= E[k] <= k, 
3 <= k <= (n-1) is determined recursively by constructing
a Hamiltonian circuit with k vertices from 
a Hamiltonian circuit with k-1 vertices, starting with
the Hamiltonian circuit of 3 vertices.  The basic 
operation consists of transposition of a pair of adjacent
vertices where the position of the pair in 
the permutation is determined by {E[k]}.  Two algorithms
treating the same example for five vertices 
are presented.  It is very easy to derive all possible n!
permutations  from the .5(n - 1 )! rosary permutations 
be cycling the permutations and by taking them in the
reverse order-procedures which can be performed 
fairly efficiently by computer. 

CACM June, 1971

Harada, K.

permutation, graph theory, scheduling, combinatorial algebra

5.32 5.39

CA710601 JB February 3, 1978  1:55 PM

2044	4	2189
2087	4	2189
2189	4	2189
2189	4	2189
2189	4	2189
2189	4	2189
2417	4	2189
2505	4	2189
2874	4	2189
2908	4	2189
3188	4	2189
1594	5	2189
2087	5	2189
2189	5	2189
2189	5	2189
2189	5	2189
2292	5	2189
2505	5	2189
521	5	2189
3191	5	2189
2189	6	2189
2189	6	2189
2292	6	2189
521	6	2189


************************

************************
Document:  CACM-1433.html
************************


A Note on Linear Programming Algorithm Design: A Combinatorial Problem

As linear programming models grow bigger and
bigger in size, much actual data that must be 
memorized is often put on magnetic tape or disk, and
consequently there is an improportionality fast 
rise in the consumption of computer timeo cut down
this expense, an ever increasing effort is made 
to design more efficient algorithms.  This paper is
meant to support the effort.  It is attempted to 
find some characteristics of the way a pivot column
is found.  The number of repetitions of a certain 
transfer of data from tape to core memory is considered.
 After some simplification, the problem is restated 
in a general way.  The generating function of the probability
distribution and the moment generating 
function of the number of repetitions is found.  Asymptotic
formulas are given <B>for the</B> moments using 
a result from a paper of S. Narumi [1].  The results
may be applied to write very efficient routines 
that search for an extreme value in a table.  Formulas
provide a means of calculating the computer timings 
in this case.

CACM May, 1966

Roes, P. B. M.

CA660504 JB March 3, 1978  10:10 AM

1433	5	1433
1433	5	1433
1433	5	1433


************************



A Note on Linear Programming Algorithm Design: A Combinatorial Problem

As linear programming models grow bigger and
bigger in size, much actual data that must be 
memorized is often put on magnetic tape or disk, and
consequently there is an improportionality fast 
rise in the consumption of computer timeo cut down
this expense, an ever increasing effort is made 
to design more efficient algorithms.  This paper is
meant to support the effort.  It is attempted to 
find some characteristics <B>of the</B> way a pivot column
is found.  The number of repetitions of a certain 
transfer of data from tape to core memory is considered.
 After some simplification, the problem is restated 
in a general way.  The generating function of the probability
distribution and the moment generating 
function of the number of repetitions is found.  Asymptotic
formulas are given for the moments using 
a result from a paper of S. Narumi [1].  The results
may be applied to write very efficient routines 
that search for an extreme value in a table.  Formulas
provide a means of calculating the computer timings 
in this case.

CACM May, 1966

Roes, P. B. M.

CA660504 JB March 3, 1978  10:10 AM

1433	5	1433
1433	5	1433
1433	5	1433


************************

************************
Document:  CACM-2161.html
************************


An Algorithm <B>for the</B> Blocks and Cutnodes of a Graph (Corrigendum)

CACM September, 1971

Paton, K.

CA710903 JB February 2, 1978  2:24 PM

2161	5	2161
2161	5	2161
2161	5	2161


************************

************************
Document:  CACM-2081.html
************************


Some Complete Calculi for Matrices

A matrix calculus is introduced with the intention of developing data structures
suitable for a high level algorithmic language for mathematical programming.  
The paper investigates how the special structure of matrices can be described
and utilized for efficient computing by saving memory space and
superfluous operations.  Sequences of Matrices (and sequences of sequences
of matrices) are considered, and matrix operators areext
ended to sequence operators and cumulative operators.  Algorithms
are given which use symbol manipulation of matrix expressions so
as <B>to find</B> the forms best suited for computation.  These forms are
called normal forms.  Several completeness results are obtained
in the sense that for each expression an equivalent expression
in normal form can be found within a specified calculus.

CACM April, 1970

Bayer, R.
Witzgall, C.

complete calculus, data structures, linear
programming, matrix, matrix concatenation,
matrix sequences, programming languages,
sequence operations, symbol manipulation

4.12 4.22 5.14 5.41

CA700403 JB February 13, 1978  3:18 PM

2081	5	2081
2081	5	2081
2081	5	2081
2253	5	2081
2254	5	2081
2081	6	2081
2081	6	2081
437	6	2081


************************

************************
Document:  CACM-2949.html
************************


A Correctness Proof of a Topology Information
Main tenance Protocol for a Distributed Computer 
Network

In order <B>for the</B> nodes of a distributed computer
network to communicate, each node must have 
information about the network's topology.  Since nodes
and links sometimes crash, a scheme is needed 
to update this information.  One of the major constrain ts
on such a topology information scheme is that 
it may not involve a central controller.  The Topology
Information Protocol that was implemented on the 
MERIT Computer Network is presented and explained; this
protocol is quite general and could be implemented 
on any computer network.  It is based on Baran's "Hot
Potato Heuristic Routing Doctrine."  A correctness 
proof of this Topology Information Protocol is also presented.

CACM July, 1977

Tajibnapis, W. D.

distributed computer network, correctness proofs,
computer networks, distributed control, network 
topology, routing problem in networks, distributed operating
system, store and forward packet switching, 
store and forward message switching, traffic control

3.81 4.32

CA770703 JB December 28, 1977  11:59 AM

2949	5	2949
2949	5	2949
2949	5	2949


************************



A Correctness Proof of a Topology Information
Main tenance Protocol for a Distributed Computer 
Network

In order for the nodes of a distributed computer
network to communicate, each node must have 
information about the network's topology.  Since nodes
and links sometimes crash, a scheme is needed 
to update this information.  One of the major constrain ts
on such a topology information scheme is that 
it may not involve a central controller.  The Topology
Information Protocol that was implemented <B>on the</B> 
MERIT Computer Network is presented and explained; this
protocol is quite general and could be implemented 
on any computer network.  It is based on Baran's "Hot
Potato Heuristic Routing Doctrine."  A correctness 
proof of this Topology Information Protocol is also presented.

CACM July, 1977

Tajibnapis, W. D.

distributed computer network, correctness proofs,
computer networks, distributed control, network 
topology, routing problem in networks, distributed operating
system, store and forward packet switching, 
store and forward message switching, traffic control

3.81 4.32

CA770703 JB December 28, 1977  11:59 AM

2949	5	2949
2949	5	2949
2949	5	2949


************************



A Correctness Proof of a Topology Information
Main tenance Protocol for a Distributed Computer 
Network

In order for the nodes of a distributed computer
network to communicate, each node must have 
information about the network's topology.  Since nodes
and links sometimes crash, a scheme is needed 
to update this information.  One <B>of the</B> major constrain ts
on such a topology information scheme is that 
it may not involve a central controller.  The Topology
Information Protocol that was implemented on the 
MERIT Computer Network is presented and explained; this
protocol is quite general and could be implemented 
on any computer network.  It is based on Baran's "Hot
Potato Heuristic Routing Doctrine."  A correctness 
proof of this Topology Information Protocol is also presented.

CACM July, 1977

Tajibnapis, W. D.

distributed computer network, correctness proofs,
computer networks, distributed control, network 
topology, routing problem in networks, distributed operating
system, store and forward packet switching, 
store and forward message switching, traffic control

3.81 4.32

CA770703 JB December 28, 1977  11:59 AM

2949	5	2949
2949	5	2949
2949	5	2949


************************



A Correctness Proof of a Topology Information
Main tenance Protocol for a Distributed Computer 
Network

In order for the nodes of a distributed computer
network to communicate, each node must have 
information about the network's topology.  Since nodes
and links sometimes crash, a scheme is needed 
to update this information.  One of the major constrain ts
on such a topology information scheme is that 
it may not involve a central controller.  The Topology
Information Protocol that was implemented on the 
MERIT Computer Network is presented and explained; this
protocol is quite general and could be implemented 
on any computer network.  It is <B>based on</B> Baran's "Hot
Potato Heuristic Routing Doctrine."  A correctness 
proof of this Topology Information Protocol is also presented.

CACM July, 1977

Tajibnapis, W. D.

distributed computer network, correctness proofs,
computer networks, distributed control, network 
topology, routing problem in networks, distributed operating
system, store and forward packet switching, 
store and forward message switching, traffic control

3.81 4.32

CA770703 JB December 28, 1977  11:59 AM

2949	5	2949
2949	5	2949
2949	5	2949


************************

************************
Document:  CACM-3040.html
************************


Synthesizing Constraint Expressions

A constraint network representation is presented
for a combinatorial search problem: finding 
values for a set of variables subject to a set of constraints.
 A theory of consistency levels in such 
networks is formulated, which is related to problems
of backtrack tree search efficiency.  An algorithm 
is developed that can achieve any level of consistency
desired, in order to preprocess the problem for 
subsequent backtrack search, or to function as an alternative
to backtrack search by explicitly determining 
all solutions.

CACM November, 1978

Freuder, E.

Backtrack, combinatorial algorithms, constraint
networks, constraint satisfaction, <B>graph coloring</B>, 
network consistency, relaxation, scene labeling, search

3.63 3.64 5.25 5.30 5.32

CA781111 DH January 22, 1979  3:43 PM

1504	4	3040
3040	4	3040
1145	5	3040
3040	5	3040
3040	5	3040
3040	5	3040


************************

************************
Document:  CACM-2832.html
************************


Faster Retrieval from Context Trees (Corrigendum)

Context trees provide a convenient way of
storing data which is to be viewed as a hierarchy 
of contexts.  This note presents an algorithm which improves
on previous context tree retrieval algorithms. 
It is based on the observation that in typical uses context
changes are infrequent relative to retrievals, 
so that data can be cached to speed up retrieval.  A retrieval
is started from the position <B>of the</B> previous 
retrieval and auxiliary structures are built up to make
the search rapid.  Algorithms for addition and 
deletion of data and for garbage collection are outlined.

CACM September, 1976

Wegbreit, B.

context trees, frame problem, variable bindings, data structures

3.69 3.74 4.10

CA760907 JB January 4, 1978  8:49 AM

2832	5	2832
2832	5	2832
2832	5	2832


************************



Faster Retrieval from Context Trees (Corrigendum)

Context trees provide a convenient way of
storing data which is to be viewed as a hierarchy 
of contexts.  This note presents an algorithm which improves
on previous context tree retrieval algorithms. 
It is based <B>on the</B> observation that in typical uses context
changes are infrequent relative to retrievals, 
so that data can be cached to speed up retrieval.  A retrieval
is started from the position of the previous 
retrieval and auxiliary structures are built up to make
the search rapid.  Algorithms for addition and 
deletion of data and for garbage collection are outlined.

CACM September, 1976

Wegbreit, B.

context trees, frame problem, variable bindings, data structures

3.69 3.74 4.10

CA760907 JB January 4, 1978  8:49 AM

2832	5	2832
2832	5	2832
2832	5	2832


************************



Faster Retrieval from Context Trees (Corrigendum)

Context trees provide a convenient way of
storing data which is to be viewed as a hierarchy 
of contexts.  This note presents an algorithm which improves
on previous context tree retrieval algorithms. 
It is <B>based on</B> the observation that in typical uses context
changes are infrequent relative to retrievals, 
so that data can be cached to speed up retrieval.  A retrieval
is started from the position of the previous 
retrieval and auxiliary structures are built up to make
the search rapid.  Algorithms for addition and 
deletion of data and for garbage collection are outlined.

CACM September, 1976

Wegbreit, B.

context trees, frame problem, variable bindings, data structures

3.69 3.74 4.10

CA760907 JB January 4, 1978  8:49 AM

2832	5	2832
2832	5	2832
2832	5	2832


************************

************************
Document:  CACM-2819.html
************************


Experiments in Text File Compression

A system for the compression of data files,
viewed as strings of characters, is presented. 
 The method is general, and applies equally well to
English, to PL/I, or to digital data.  The system 
consists of an encoder, an analysis program, and a decoder.
  Two <B>algorithms for</B> encoding a string differ 
slightly from earlier proposals.  The analysis program attempts
to find an optimal set of codes for representing 
substrings of the file.  Four new algorithms for this
operation are described and compared.  Various 
parameters in the algorithms are optimized to obtain
a high degree of compression for sample texts.

CACM November, 1976

Rubin, F.

text compression, data file compaction, Huffman
codes, N-gram encoding, comparison of algorithms

3.7 3.73 4.33

CA761104 JB January 3, 1978  3:26 PM

2530	4	2819
2623	4	2819
2819	4	2819
2537	5	2819
2819	5	2819
2819	5	2819
2819	5	2819


************************



Experiments in Text File Compression

A system <B>for the</B> compression of data files,
viewed as strings of characters, is presented. 
 The method is general, and applies equally well to
English, to PL/I, or to digital data.  The system 
consists of an encoder, an analysis program, and a decoder.
  Two algorithms for encoding a string differ 
slightly from earlier proposals.  The analysis program attempts
to find an optimal set of codes for representing 
substrings of the file.  Four new algorithms for this
operation are described and compared.  Various 
parameters in the algorithms are optimized to obtain
a high degree of compression for sample texts.

CACM November, 1976

Rubin, F.

text compression, data file compaction, Huffman
codes, N-gram encoding, comparison of algorithms

3.7 3.73 4.33

CA761104 JB January 3, 1978  3:26 PM

2530	4	2819
2623	4	2819
2819	4	2819
2537	5	2819
2819	5	2819
2819	5	2819
2819	5	2819


************************



Experiments in Text File Compression

A system for the compression of data files,
viewed as strings of characters, is presented. 
 The method is general, and applies equally well to
English, to PL/I, or to digital data.  The system 
consists of an encoder, an analysis program, and a decoder.
  Two algorithms for encoding a string differ 
slightly from earlier proposals.  The analysis program attempts
<B>to find</B> an optimal set of codes for representing 
substrings of the file.  Four new algorithms for this
operation are described and compared.  Various 
parameters in the algorithms are optimized to obtain
a high degree of compression for sample texts.

CACM November, 1976

Rubin, F.

text compression, data file compaction, Huffman
codes, N-gram encoding, comparison of algorithms

3.7 3.73 4.33

CA761104 JB January 3, 1978  3:26 PM

2530	4	2819
2623	4	2819
2819	4	2819
2537	5	2819
2819	5	2819
2819	5	2819
2819	5	2819


************************



Experiments in Text File Compression

A system for the compression of data files,
viewed as strings of characters, is presented. 
 The method is general, and applies equally well to
English, to PL/I, or to digital data.  The system 
consists of an encoder, an analysis program, and a decoder.
  Two algorithms for encoding a string differ 
slightly from earlier proposals.  The analysis program attempts
to find an optimal set of codes for representing 
substrings <B>of the</B> file.  Four new algorithms for this
operation are described and compared.  Various 
parameters in the algorithms are optimized to obtain
a high degree of compression for sample texts.

CACM November, 1976

Rubin, F.

text compression, data file compaction, Huffman
codes, N-gram encoding, comparison of algorithms

3.7 3.73 4.33

CA761104 JB January 3, 1978  3:26 PM

2530	4	2819
2623	4	2819
2819	4	2819
2537	5	2819
2819	5	2819
2819	5	2819
2819	5	2819


************************

************************
Document:  CACM-1456.html
************************


Storage and Retrieval of Aspects of Meaning in Directed Graph Structures

An experimental system that uses LISP to make
a conceptual dictionary is described.  The dictionary 
associates with each English word the syntactic information,
definitional material, and references to 
the contexts in which it has been used to define other words.
 Such relations as class inclusion, possession, 
and active or passive actions are used as definitional
material.  The resulting structure serves as a 
powerful vehicle for research <B>on the</B> logic of question answering.
 Examples of methods of inputting information 
and answering simple English questions are given.  An
important conclusion is that, although LISP and 
other list processing languages are ideally suited for
producing complex associative structures, they 
are inadequate vehicles for language processing on any
large scale-at east until they can use auxiliary 
memory as a continuous extension of core memory.

CACM March, 1966

Simmons, R. F.

CA660316 JB March 3, 1978  11:25 AM

1155	4	1456
1456	4	1456
1468	4	1456
1515	4	1456
1699	4	1456
1856	4	1456
2127	4	1456
1324	5	1456
1456	5	1456
1456	5	1456
1456	5	1456


************************

************************
Document:  CACM-1432.html
************************


Incorporation of Nonstandard Input/Output Devices into FORTRAN Systems

A FORTRAN system may readily be modified to
handle input/output with nonstandard media <B>on the</B> 
same basis on which it handles the standard media.  This
is done by providing a character-handling subroutine 
suited to the nonstandard medium and arranged to be called
by an otherwise unused output statement type 
or unit number. This method was used to control output
of alphanumeric information on a digital graph 
plotter.

CACM May, 1966

Cohn, C. E.

CA660505 JB March 3, 1978  10:01 AM

1432	5	1432
1432	5	1432
1432	5	1432


************************

************************
Document:  CACM-2674.html
************************


Scan Conversion Algorithms for a Cell Organized Raster Display

Raster scan computer graphics with "real time"
character generators have previously been limited 
to alphanumeric characters.  A display has been described
which extends the capabilities of this organization 
to include general graphics.  Two fundamentally different
scan conversion algorithms which have been 
developed to support this display are presented.  One
is most suitable to non-interactive applications 
and the other to interactive applications.  The algorithms
were implemented in Fortran <B>on the</B> CDC 6400 
computer.  Results obtained from the implementations show
that the noninteractive algorithms can significantly 
reduce display file storage requirements at little cost
in execution time over that of a conventional 
raster display.  The interactive algorithm can improve
response time and reduce storage requirements.

CACM March, 1974

Barrett, R. C.
Fordan, B. W. Jr.

graphics, scan conversion, raster display, line
drawing, discrete image, dot generation, matrix
displays

4.41 6.35 8.2

CA740309 JB January 18, 1978  11:08 AM

1891	4	2674
2211	4	2674
2421	4	2674
2674	4	2674
2674	4	2674
2674	4	2674
2674	4	2674
2687	4	2674
2687	4	2674
2828	4	2674
1741	5	2674
2004	5	2674
2421	5	2674
2674	5	2674
2674	5	2674
2674	5	2674
2687	5	2674


************************

************************
Document:  CACM-2980.html
************************


The Editing  of Picture Segmentations Using Local Analysis of Graphs

A major problem in picture processing is the
elimination of the large number of spurious regions 
that result from an initial segmentation by region growing
techniques.  Such regions have been eliminated 
either <B>on the</B> basis of semantic information or on the
basis of size and contrast.  A scheme is presented 
which performs eliminations on the basis of local properties
of the region adjacency graph.  The scheme 
is based on definitions of graph properties which are
satisfied when a spurious region is present; then 
editing is equivalent to fast graph operations.  A number of examples are shown.

CACM April, 1977

Tanimoto, S. L.
Pavlidis, T.

picture processing, pattern recognition, segmentation, region editing 

3.63

CA770402 JB December 29, 1977  6:22 AM

2980	4	2980
2523	5	2980
2980	5	2980
2980	5	2980
2980	5	2980


************************



The Editing  of Picture Segmentations Using Local Analysis of Graphs

A major problem in picture processing is the
elimination <B>of the</B> large number of spurious regions 
that result from an initial segmentation by region growing
techniques.  Such regions have been eliminated 
either on the basis of semantic information or on the
basis of size and contrast.  A scheme is presented 
which performs eliminations on the basis of local properties
of the region adjacency graph.  The scheme 
is based on definitions of graph properties which are
satisfied when a spurious region is present; then 
editing is equivalent to fast graph operations.  A number of examples are shown.

CACM April, 1977

Tanimoto, S. L.
Pavlidis, T.

picture processing, pattern recognition, segmentation, region editing 

3.63

CA770402 JB December 29, 1977  6:22 AM

2980	4	2980
2523	5	2980
2980	5	2980
2980	5	2980
2980	5	2980


************************



The Editing  of Picture Segmentations Using Local Analysis of Graphs

A major problem in picture processing is the
elimination of the large number of spurious regions 
that result from an initial segmentation by region growing
techniques.  Such regions have been eliminated 
either on the basis of semantic information or on the
basis of size and contrast.  A scheme is presented 
which performs eliminations on the basis of local properties
of the region adjacency graph.  The scheme 
is <B>based on</B> definitions of graph properties which are
satisfied when a spurious region is present; then 
editing is equivalent to fast graph operations.  A number of examples are shown.

CACM April, 1977

Tanimoto, S. L.
Pavlidis, T.

picture processing, pattern recognition, segmentation, region editing 

3.63

CA770402 JB December 29, 1977  6:22 AM

2980	4	2980
2523	5	2980
2980	5	2980
2980	5	2980
2980	5	2980


************************

************************
Document:  CACM-1563.html
************************


A Method for Finding Hamilton Paths and Knight's Tours

The use of Warnsdorff's rule for finding a
knight's tour is generalized and applied to the 
problem of finding a Hamilton path in a graph.  A graph-theoretic
justification <B>for the</B> method is given.

CACM July, 1967

Pohl, I.

CA670710 JB February 28, 1978  8:28 AM

1563	5	1563
1563	5	1563
1563	5	1563


************************

************************
Document:  CACM-2052.html
************************


Scheduling to Reduce Conflict in Meetings

Conflicts in scheduling can be treated as defining an undirected linear graph 
independently <B>of the</B> relation of the activities in conflict to additional 
constraints of time and space.  Each connected component of such a graph,
which can be found by an algorithm described by Gotlieb and Corneil, 
corresponds to a set of events that must be scheduled at different times.

CACM June, 1970

Grimes, J. E.

allocation, conflict matrix, connected component, scheduling, spanning
tree, undirected linear graph

1.90 3.51 3.59 5.32

CA700603 JB February 13, 1978  11:55 AM

1609	4	2052
1847	4	2052
1961	4	2052
2052	4	2052
2052	4	2052
2052	4	2052
2052	4	2052
2209	4	2052
1008	5	2052
1013	5	2052
1504	5	2052
1540	5	2052
2052	5	2052
2052	5	2052
2052	5	2052


************************

************************
Document:  CACM-2568.html
************************


A Graph Formulation of a School Scheduling Algorithm

The problem classically titled "The Examination
Schedule Problem" takes various forms in the 
literature.  Most <B>of the</B>se formulations can be presented
in the terminology of classical Network Theory. 
 One such formulation is:  Given a nondirected network,
partition its nodes into a minimal number of 
subsets such that no two members of the same subset
are connected by anarc.  An obvious lower limit 
to this number is the size of the largest strongly connected
subgraph.  Kirchgassner proved that an upper 
limit is this size plus one.  One logical extension of
the previous work is the introduction of variable 
length examinations where W(I) is the number of periods
for exam I.  The object of this paper is to generalize 
the definition of largest strongly connected subgraph
to include the weighting of nodes, to present an 
approximate algorithm which usually finds the largest
strongly connected subgraph, and to discuss the 
application of this algorithm to the solution of
school scheduling and exam scheduling problems.

CACM December, 1974

Salazar, A.
Oakford, R. V.

scheduling, school scheduling, examination scheduling,
nondirected network, graph, subgraph, strongly 
connected subgraph

3.51 3.52

CA741206 JB January 13, 1978  4:37 PM

2568	5	2568
2568	5	2568
2568	5	2568


************************

